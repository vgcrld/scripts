<h1>Chart - 1</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU (Logical) Utilization
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Logical CPU Utilization</b> (%Busy) for a host.
      </div>
      <div class='definitions'>
        <ul>
          <li><b># of Logical CPUs</b> represents the number of logical processors (LPs) presented/assigned to this host.  If Hyper-Threading (HT) is enabled, the number of LPs will be greater than the <b># of Virtual CPUs</b> in the <b>CPU Consumed</b> chart.  Hyper-threading, also known as Simultaneous Multi-Threading (SMT), is the ability of a single physical processor (core) to concurrently process multiple program threads from the operating system.  Two or more program threads can run on one physical processor (core) at the same time.  Hyper-threading is a good choice when overall throughput is more important than the throughput of an individual thread.  For example, Web and database servers are good candidates.</li>
        </ul>
        <ul>
          <li><b>User</b> represents the percentage of time the host's logical CPUs spend in user mode.  Programs running in USER mode don't have access to the kernel or its data segments, except indirectly through system calls.  A program in this mode can only affect its own execution environment and runs in the processor-unprivileged state.</li>
        </ul>
        <ul>
          <li><b>System/Privileged</b> represents the percentage of time the host's logical CPUs spend in system/privileged mode.  Programs that run in this mode include interrupt handlers, base kernel and kernel extensions (including device drivers).  Programs running in system/privileged mode have read/write access to global kernel address space and to the kernel data in the process private segment when running in the process context.  Context switch time, system calls, device interrupts, CIFS/NFS I/O and anything else being processed by the kernel is considered system time.</li>
        </ul>
        <ul>
          <li><b>Wait/Interrupt</b> details the percentage of time the CPU was idle with pending I/O interrupts (typically disk I/O, including local and CIFS/NFS-mounted file systems).</li>
        </ul>
      </div>
      <div class='notes'>
        Traditionally REAL CPU Consumed is the sum of user + system, but in virtual environments, often wait and idle processing should be considered as they are included in the Physical CPU consumed by a virtual host.  Because some operating systems do not poll CPU statistics for each core at the same time interval, there may be instances when CPU utilization will exceed 100%.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 2</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Run Queue/Processor Queue Length
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>
          This chart displays the <b>Run Queue</b> of the host (known as <b>Processor Queue Length</b> for Windows).  The run queue indicates the number of active running processes on the host that are presently consuming resources.
        </p>
        <p>
          For example, if the process 'httpd' is running, but not being accessed, it will not be 'counted' in the run queue.  In this case, the httpd process is sleeping, waiting for the next interrupt to begin processing.  When an interrupt occurs, the httpd process will be moved to the run queue, and the run queue number will be increased by 1.
        </p>
        <p>
          There are several opinions and rule-of-thumbs on the run queue number, but it depends on your particular workload and service level objectives.  If 'response time' is most important, you may want it no higher than 1 to 2 times the number of CPUs (virtual or real) allocated to the host.  If 'job throughput' is important, 3 to 4+ times the number of CPUs may be sufficient to keep the processors busy, especially with SMT/Hyper-Threading on.  A high run queue may be a sign of an overcommitted system, CPU intensive process(es) hogging the queue or a user/job-scheduling package or script mistakenly running too many processes at once.  Context Switch/System Calls, Processes Forks/EXECs and the CPU Utilization charts may be of help.
        </p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 3</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU Consumed vs. Entitlement
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'></div>
      <div class='definitions'>
        <ul>
          <li><b># of Virtual Processors</b> represents the number of virtual processors (VP) presented/assigned to this LPAR.  This is configured in the LPAR definition.</li>
          <li><b># of Logical CPUs</b> is the number of logical processors (LP) defined by the OS for this LPAR.  If SMT (Hyper-Threading) is enabled, two or more LPs will be assigned to each VP/core.  SMT can increase processor utilization by allowing multiple program threads to use a single virtual processor at the same time.  SMT was introduced with AIX 5.3 and POWER5 servers.</li>
          <li><b>Physical CPU Consumed</b> is the number of physical processor units consumed (Used) by this LPAR.  This is the total amount of physical CPU usage.  The "CPU Virtual/Core Utilization" chart can be referenced for a breakdown of this consumption (User, System, IOwait, Idle).</li>
          <li><b>Entitlement</b> is the number of physical processor units this LPAR is entitled to and guaranteed by the Hypervisor.  When the LPAR Physical CPU Consumption is less than the Entitlement, the LPAR (shared only) will donate excess physical CPU units to the shared pool for use by other LPARs "exceeding" their entitlement.  When the LPAR Physical CPU Consumption is greater than the Entitlement (uncapped), the LPAR will request more physical CPU from the shared pool via the Hypervisor.  This is defined in the LPAR definition.</li>
        </ul>
      </div>
      <div class='notes'>
        <p>Caution:</p>
        <p>If the average Physical CPU Consumption is greater than the Entitlement and this is a production LPAR, the Entitlement should be increased to the average or more to reduce overhead.  The "CPU Entitlement Utilization" chart provides a quick indicator of this by showing the percent consumed against the Entitlement.  For example, whenever the Physical CPU Consumption is over 100%, the LPAR is using more than the Entitlement setting.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 4</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Shared Pool Utilization
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'></div>
      <div class='definitions'>
        <ul>
          <li><b>Physical CPU Consumed</b> is the number of physical processor units consumed (Used) by this LPAR.  This is the total amount of physical CPU usage.  The "CPU Virtual/Core Utilization" chart can be referenced for a breakdown of this consumption (User, System, IOwait and Idle).</li>
          <li><b>Others in Shared Pool</b> is the number of physical processor units consumed (Used) by other LPARs in the same shared CPU pool.</li>
          <li><b>Entitlement</b> is the number of physical processor units this LPAR is entitled to and guaranteed by the Hypervisor.  When the LPAR Physical CPU Consumption is less than the Entitlement, the LPAR (shared only) will donate excess physical CPU units to the shared pool for use by other LPARs "exceeding" their entitlement.  When the LPAR physical CPU consumption is greater than the entitlement (uncapped), the LPAR will request more physical CPU from the shared pool via the Hypervisor.  This is configured in the LPAR definition.</li>
          <li><b>Total in Shared Pool</b> is the total number of physical processor units assigned to the Shared Pool.  If the LPAR is in an MSPP pool, this will be the MAX of the MSPP Pool.</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 5</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LPAR Weight
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>If there are a number of LPARs that exist on the managed system, we require a way to prioritize shared CPU, and how it is distributed to those partitions.  The <b>LPAR Weight</b> designates this value.  For example:</p>
        <table cellpadding='5' cellspacing='5'>
          <tr>
            <td>LPAR Name</td>
            <td>LPAR CPU Desired</td>
            <td>LPAR Weight</td>
          </tr>
          <tr>
            <td>VIO Server 1</td>
            <td>.5</td>
            <td>255</td>
          </tr>
          <tr>
            <td>DB Server 1</td>
            <td>4</td>
            <td>128</td>
          </tr>
          <tr>
            <td>App Server 1</td>
            <td>3</td>
            <td>127</td>
          </tr>
          <tr>
            <td>Static Content Server 1</td>
            <td>.2</td>
            <td>127</td>
          </tr>
        </table>
        <p>In the above example, <b>VIO server 1</b> has the highest weight (255) and therefore will always get the CPU that is required.  When this LPAR requires CPU, .5 processor will be made available to it, regardless of the CPU utilization on other LPARs.</p>
        <p>The remaining available CPU (if there is any available) is distributed to the other LPARs in order of descending weights.  In this case, 4 CPUs are available to <b>DB server 1</b>.  This CPU is pulled from the engine that is available, once higher priority LPAR CPU allocations have been satisfied.</p>
        <p>The remaining LPARs (<b>APP server 1</b> and <b>Static Content server 1</b>) will contend for the remaining CPU resources after the higher priority servers have been satisfied.  Since they are both of equal weight in terms of CPU allocation, they will contend with one another for available CPU cycles, assuming that CPU is available.  If there is no CPU available to those remaining LPARs, they will be forced to wait until CPU from the higher priority LPARs is available for use.</p>
        <p>N/A for Dedicated LPARs</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 6</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Real Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the utilization of <b>Real Memory</b> in the host.</p>
      </div>
      <div class='definitions'>
        <ul>
          <li><b>Used</b> indicates the amount of real memory that is being used.</li>
          <li><b>Allocated</b> indicates the amount of real memory assigned to this host.</li>
          <li><b>Free</b> indicates the amount of real memory that is not being used; represented by the open area between "Used" and "Allocated"</li>
        </ul>
      </div>
      <div class='notes'>
        <p>Note:</p>
        If Huge/Large Page Memory support has been detected, the other Memory and Huge/Large Page Memory charts should be referenced to fully understand the "Used" and "Free" Real Memory breakdown.  It is possible to have "Free" memory, but reserved for Huge/Large Pages and unusable for general use.  This could lead to a shortage of "Free" memory, causing system paging, even though Free memory is displayed.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 7</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Virtual Memory/Paging Space
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the utilization of paging space in the host.
        <ul>
          <li><b>Used</b> indicates the amount of paging space which is being used</li>
          <li><b>Allocated</b> indicates the amount of paging space allocated to the host</li>
          <li><b>Free</b> indicates the amount of paging space which is not being used; represented by the open area between "Used" and "Allocated"</li>
        </ul>
        <br>
      </div>
      <div class='notes'>
        <p>Notes:</p>
        If the Paging Space becomes fully used, the OS will not allow new processes to be started and will begin to terminate existing processes in an attempt to survive.  A gradual increase of Paging Space usage over time should be investigated immediately to avoid a system outage.
        <ul>
          <li>Things to Check:</li>
          <ul>
            <li>If the Scan to Free Ratio is greater than 4 on average, then memory is very active (over 75% utilized), which could be a sign of needing more memory, memory is over committed or tuning is required.</li>
            <li>"System Paging" chart for thrashing</li>
            <li>"Real Memory" and "Memory Use" charts for the past month to see if memory allocations were reduced</li>
            <li>DB memory buffers may have been increased or additional database instances were started</li>
            <li>JAVA HEAP/memory was increased in applications</li>
            <li>New applications were added using more memory</li>
            <li>Memory leaks, often with new applications or JAVA applications</li>
            <li>"Large Page Support" was activated and over allocated</li>
          </ul>
          <br>
          <li>If a Huge/Large Page Memory alert was raised during the selected time range, and a high Scan/Free Ratio is occurring, please refer to the "Huge/Large Page Memory" charts and their Help Panels to identify if free Large Page memory exists, which can be unallocated and made available for general use.</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 8</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Memory Use
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the allocation of real memory in the LPAR.  This is displayed as a combination of the following three elements:
      </div>
      <div class='definitions'>
        <ul>
          <li><b>System memory</b></li>
          <ul class='secondary-list'>
            <li>Memory that is allocated to the system functions and their operations</li>
          </ul>
          <li><b>Process memory</b></li>
          <ul class='secondary-list'>
            <li>Memory that caches elements other than system functions</li>
            <li>This is typically application functions and associated libraries</li>
          </ul>
          <li><b>Filesystem cache memory</b></li>
          <ul class='secondary-list'>
            <li>This is the remaining memory that can be utilized to cache filesystem data.</li>
            <li>The upper limit of this is defined by the outer edges of the minperm and maxperm settings of the system.</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 9</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    VMM Parameters
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows memory utilization relative to the <b>Virtual-Memory Manager (VMM)</b> tunables minperm% and maxperm%.  Look for computational and Filesystem Cache (numperm) to fall within the bounds set by minperm% and maxperm%.</p>
      </div>
      <div class='definitions'>
        <ul>
          <li><b>Computational</b> indicates the percentage of real memory being used for System and Process operations</li>
          <li><b>Filesystem Cache (numperm)</b> indicates the portion of memory being used for filesystem caching.  Filesystem cache usage can be tuned in the AIX Virtual Memory Manager (VMM).</li>
          <li><b>VMO minperm</b> indicates the point (in percentage of the total number of memory frames) below which the page-stealer will steal file or computational pages regardless of repaging rates.  It might be useful to decrease this parameter if a large number of file pages in memory is causing working storage pages to be replaced.  If some files are known to be read repetitively, and I/O rates do not decrease with time from startup, minperm may be too low.</li>
          <li><b>VMO maxperm</b> Specifies the point above which the page-stealing algorithm steals only file pages.  This value is expressed as a percentage of the total real-memory page frames in the system.  Reducing this value may reduce or eliminate page replacement of working storage pages caused by high number of file page accesses.  Increasing this value may help NFS servers that are mostly read-only.  For example, if some files are known to be read repetitively, and I/O rates do not decrease with time from startup, maxperm may be too low.</li>
        </ul>
      </div>
      <div class='notes'>
        <p>Note:</p>
        <p>If Large-Page Support is in use, the maxperm% will appear lower than the VMO tunable parameter is set.  In this case, the computational and numperm values may be higher than maxperm%.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Large Page Memory (Size)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>Great care should be taken to fully understand how <b>Huge/Large Page Memory</b> works as it can cause severe memory constraints, paging and memory thrashing if used incorrectly.  For example, if the chart shows 4000 MB (4 GB) of allocated memory but 0 MB Used, then 4 GB of "Free" memory exists, though it does not show up on the free memory list, and it is NOT for use by general applications.  The system could incur system paging and poor response time because of a shortage of memory, while this 4 GB is reserved, but unavailable to unauthorized applications.</p>
        <p>You can quickly identify if the Huge/Large Page Memory is over or under allocated.  If the trend shows continual free memory (over allocation = allocated - used), consideration should be given to reducing the allocation, giving memory back for general use.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 11</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    System Paging
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <div class='definitions'>
          <p>For <b>AIX</b>: vmstat "pi" and "po" columns</p>
          <p>For <b>Linux</b>: /proc/vmstat "pswpin" and "pswpout" Page/Swap-Ins from</p>
          <p>For <b>Windows</b>: perfmon "Pages Input/sec" and "Pages Output/sec"</p>
          <p>Page/Swap-Ins from Paging/Swap Space: the rate/sec of page-in operations</p>
          <p>Page/Swap-Outs to Paging/Swap Space: the rate/sec of page-out operations</p>
        </div>
      </div>
      <div class='notes'>
        <p>Notes:</p>
        <ul>
          <li>If Page/Swap-Ins is consistently higher than Page/Swap-Outs this may indicate thrashing.</li>
          <li>If a Huge/Large Page Memory alert was raised during the selected time range, and system paging is occurring, please refer to the "Huge/Large Page Memory" charts and their Help Panels to identify if Free Large Page memory exists, which can be unallocated and made available for general use.</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 12</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Paging
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the number of <b>Filesystem I/O</b> reads and writes.</p>
      </div>
      <div class='definitions'>
        <p>For <b>AIX</b>: vmstat "fi" and "fo" columns (pages per second)</p>
        <p>For <b>Linux</b>: /proc/vmstat "pgpgin" and "pgpgout" (KB per second)</p>
        <p>For <b>Windows</b>: perfmon "File Read Bytes/sec" and "File Write Bytes/sec" reported as KB/sec <b>(one page = 1 KB/sec)</b></p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 13</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Memory (Scan / Free Ratio)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the number of memory pages scanned as a ratio to the number of memory pages freed.</p>
        <p>When the memory free-list is low, and processes make requests for memory, the CPU will spend some time scanning for memory pages that can be freed.  If the number of pages freed is too small, the CPU will continue to spend time scanning for pages to be freed.</p>
        <p>If the scan to free ratio is greater than 4 on average, then memory is very active (over 75% utilized), which could be a sign of needing more memory, memory is over committed or tuning is required.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <ul>
          <li>Things to Check:</li>
          <ul class='nested'>
            <li>"System Paging" chart for thrashing</li>
            <li>"Real Memory" and "Memory Use" charts for the past month to see if memory allocations were reduced</li>
            <li>DB memory buffers may have been increased or additional database instances were started</li>
            <li>JAVA HEAP/memory was increased in applications</li>
            <li>New applications were added using more memory</li>
            <li>Memory leaks, often with new applications or JAVA applications</li>
            <li>"Large Page Support" was activated and over allocated</li>
          </ul>
          <li>If a Huge/Large Page Memory alert was raised during the selected time range, and a high Scan/Free Ratio is occurring, please refer to the "Huge/Large Page Memory" charts and their Help Panels to identify if free Large Page memory exists, which can be unallocated and made available for general use.</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 14</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Processes (Context Switch / System Calls)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <div class='definitions'>
          <ul>
            <li><b>Context Switches</b> shows process switches (changes between user applications)</li>
            <li><b>System Calls</b> shows system calls (when application requests OS services)</li>
          </ul>
          <p>A high number of Context Switches and System Calls may be a sign of a script or job which is looping or inefficient.</p>
        </div>
      </div>
      <div class='notes'>
        <p>Caution:</p>
        <p>System Calls may be zero when the OS does not provide these statistics.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 15</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Processes (Forks / EXECs)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'></div>
      <div class='definitions'>
        <ul>
          <li><b>Forks</b> shows new process creation (when a clone of a current process is created)</li>
          <li><b>Execs</b> shows starts of new program code (over-writing current process with a new program)</li>
        </ul>
        <p>A high number of Fork and Execs may be a sign of a script or job which is looping and continually spawning itself.</p>
      </div>
      <div class='notes'>
        <p>Caution:</p>
        <p>Execs may be zero when the OS does not provide these statistics.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 16</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Adapter Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the total throughput that exists on an interface in KB/s.  It is important to note that these values are expressed as a rate, and does not reflect the total value on the various adapters.  This can help determine the average throughput of various adapters over a period of time, helping to determine bandwidth estimation for events such as replication or total network capacity utilization.  It can also be used to determine adapter throughput balancing.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 17</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Adapter Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the read throughput that exists on an interface in KB/s.  It is important to note that these values are expressed as a rate, and does not reflect the total value on the various adapters.  This can help determine the average throughput of various adapters using a read method over a period of time, helping to determine bandwidth estimation for events such as replication or total network capacity utilization.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 18</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Adapter Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the write throughput that exists on an interface in KB/s.  It is important to note that these values are expressed as a rate, and does not reflect the total value on the various adapters.  This can help determine the average throughput of various adapters using a write method over a period of time, helping to determine bandwidth estimation for events such as replication or total network capacity utilization.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 19</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Adapter Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the total I/O adapter transfer rate for each adapter.  It is important to note that these values are expressed as a rate, and does not reflect the total value on the various adapters.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 20</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Read/Write and Transfer Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual disk data rate of the system in question, coupled with the transfer operations per second.  The disk data rate is labeled in KB/s.  This is indicative of the actual data rate transferring from/to the disk in both read and write operations, and the end value that is displayed is the combined rate of both operations at the given time period.</p>
        <p>The Y-axis on the right-hand side of the graph displays the actual transfer operations per second.  This helps to correspond the data rate throughput with the associated operations per second.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>
          On
          <b>Linux,</b>
          these values represent the sum of all block devices named hd[a-z]+ (IDE) and sd[a-z]+ (SCSI)
        </p>
        <p>
          On
          <b>AIX,</b>
          these values represent the sum of all block devices that are NOT named cd[0-9]+, dac[0-9]+, hdiskpower[0-9]+ or vpath[0-9]+
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 21</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the amount of data in KB per second READ from each disk of the host.  You can quickly identify heavy READ disks or if there is an even distribution of READs across the disks.  By default, a "stacked area" view is displayed to quickly illustrate the total sum of disk READs in KB/s for the host.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 22</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the amount of data in KB per second WRITTEN to each disk of the host.  You can quickly identify heavy WRITE disks or if there is an even distribution of WRITEs across the disks.  By default, a "stacked area" view is displayed to quickly illustrate the total sum of disk WRITEs in KB/s for the host.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 23</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the number of transfers per second (IO/s) from/to each disk of the host.  You can quickly identify heavy READ and WRITE disks or if there is an even distribution of IOs across the disks.  By default, a "stacked area" view is displayed to quickly illustrate the total transfers per second for the host.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 24</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the average size (blocksize) of the transfers in KB per second for each disk of the host.  You can quickly identify large vs. small transfer sizes.  Large transfer sizes often indicate sequential processing workloads while small transfer sizes often indicate random transactional workloads.  This is a <b>non-stacked line</b> view, which quickly allows the large size transfers to stand above the small size transfers.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 25</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Network Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the RECEIVE and SEND network throughput of all the interfaces, excluding loopback, in KB/s for the host.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 26</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Network Packets Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the RECEIVE and SEND network packets of all the interfaces, excluding loopback, in Packets/s for the host.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 29</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Physical CPU Utilization Summary (NOT Normalized)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the total active CPU units on the managed system, as well as the
        actual physical CPU units consumed by all active
        LPARs in a stacked area view.  Depending upon the physical
        architecture (i.e., Power5, Power6, Power7, etc.), the CPUs are defined
        to an LPAR in one of the following Types-Modes:
        <ul>
          <li><b>Shared-Uncapped</b> Share unused CPU with others; can go above Entitlement</li>
          <li><b>Shared-Capped</b> Share unused CPU with others; CANNOT go above Entitlement</li>
          <li><b>Dedicated-Uncapped</b> Exclusive CPUs and NO SHARING unused CPU with others</li>
          <li><b>Dedicated-Donating</b> Guaranteed CPUs and SHARE/DONATE unused CPU with others.</li>
          Refer to IBM documentation for more information.
        </ul>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>This physical server view can be used to determine if more CPUs are needed (possibly using CUoD), or which LPARs are the largest consumers of CPU resources.  This chart can be used to determine if an LPAR requires tuning, or if an adjustment to the Weight, Entitlement, Capping or number of Virtual Processors is necessary.  The Shared Usage + Dedicated Allocation and Dedicated-Capped Allocation + Donated/Shared Usage charts should be reviewed to identify "Dedicated-Capped" LPARs with low CPU usage and over-allocated CPUs which may be reclaimed and shared with others.</p>
        <p>Since an LPAR's type and mode may have changed over the time duration selected for viewing, the additional charts referenced above should be reviewed for a thorough understanding.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 30</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host CPU (Logical) Percent Busy
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the <b>Logical Processor's CPU utilization (%Busy)</b> of all hosts on the managed system, in a "non-stacked line" view.  This is calculated by the (sum of User%+System% individual CPU records) / (# of CPU records).  If Hyper-Threading (HT) is on, the number of CPU records could be two or more per physical core/virtual CPU.  Hyper-threading, also known as Simultaneous Multi-Threading (SMT), is the ability of a single physical processor to concurrently dispatch instructions from more than one hardware thread.  Two or more hardware threads can run on one physical processor at the same time.  Hyper-threading is a good choice when overall throughput is more important than the throughput of an individual thread.  For example, Web servers and database servers are good candidates.</p>
        <p>This is a quick view of all hosts on the server to determine their CPU utilization from 0-100% according to various characteristics defined (e.g. dedicated, shared, capped, # of virtual CPUs, hyper-threading, etc.).  Traditionally if the utilization percentage is consistently 80-100%, more CPU may be required for the host, requiring more virtual or dedicated processors to be added, entitlement to be increased or a process could be processing abnormally (looping) using CPU resources and needs to be investigated.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Caution should be exercised when using this chart and one should have a thorough understanding of virtualization and hyper-threading.  For example, a host could have 4 virtual processors (cores) assigned to it and 4 logical processors (hyper-threads) per virtual processor.  This will present itself as 16 CPUs (4*4), giving the perception the host has the CPU capacity of 16 physical processors, when in fact it only has four cores.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL hosts.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 31</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Real Memory Allocation
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This is the total <b>Real Memory Allocation</b> of all the active hosts on the server in a "stacked area" view.  It is important to note that this particular chart does not illustrate the amount of memory utilized by each host in terms of actual usage, but rather the amount of real memory ALLOCATED to each host.  The chart "Host Real Memory Used" is a better indication of each host's memory usage and can be useful for an Active Memory Sharing (AMS) analysis.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 32</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Real Memory Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the utilization of real memory by all the hosts on the server in a "stacked area" view.  This chart (along with "Host Real Memory Allocation") allows one to quickly determine whether a host is using all of the allocated memory or could give some memory to another host.  Before removing memory from a host you should first view the host's memory charts to verify the memory is not in use.  You should also make sure it is not application memory (eg. file cache) and that there are no required changes to kernel parameters.  You may want to verify that the host is not currently "paging".  This chart can be useful in an Active Shared Memory (ASM) analysis.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 33</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Disk Reads + Writes Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual disk data rate throughput of all the hosts on the server in a "stacked area" view.  The disk throughput is labeled in KB/s.  This is indicative of the actual data rate transferring to/from the disk in both read and write operations, and the end value that is displayed is the combined rate of both operations at the given time period.  This server view can be used to determine which hosts have the highest throughput and if dedicated HBAs or sharing of HBAs between hosts should be considered (VIO/NPIV).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>
          On
          <b>Linux,</b>
          these values represent the sum of all block devices named hd[a-z]+ (IDE) and sd[a-z]+ (SCSI)
        </p>
        <p>
          On
          <b>AIX,</b>
          these values represent the sum of all block devices that are NOT named cd[0-9]+, dac[0-9]+, hdiskpower[0-9]+ or vpath[0-9]+
        </p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 34</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Disk Reads Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual disk data rate READ throughput of all the hosts on the server in a "stacked area" view.  The disk throughput is labeled in KB/s.  This is indicative of the actual data rate transferring from the disk in READ operations at the given time period.  This server view can be used to determine which hosts have the highest throughput and if dedicated HBAs or sharing of HBAs between hosts should be considered (VIO/NPIV).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>
          On
          <b>Linux,</b>
          these values represent the sum of all block devices named hd[a-z]+ (IDE) and sd[a-z]+ (SCSI)
        </p>
        <p>
          On
          <b>AIX,</b>
          these values represent the sum of all block devices that are NOT named cd[0-9]+, dac[0-9]+, hdiskpower[0-9]+ or vpath[0-9]+
        </p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 35</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Disk Writes Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual disk data rate WRITE throughput of all the hosts on the server in a "stacked area" view.  The disk throughput is labeled in KB/s.  This is indicative of the actual data rate transferring to the disk in WRITE operations at the given time period.  This server view can be used to determine which hosts have the highest throughput and if dedicated HBAs or sharing of HBAs between hosts should be considered (VIO/NPIV).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>
          On
          <b>Linux,</b>
          these values represent the sum of all block devices named hd[a-z]+ (IDE) and sd[a-z]+ (SCSI)
        </p>
        <p>
          On
          <b>AIX,</b>
          these values represent the sum of all block devices that are NOT named cd[0-9]+, dac[0-9]+, hdiskpower[0-9]+ or vpath[0-9]+
        </p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 36</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Disk Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total number of <b>Host Disk Transfers</b> (IO/s) that have occurred on all the hosts on the server in a "stacked area" view.  These values consist of read and write transfer operations on all adapters.  This server view can be used to determine which hosts have the highest IO/s rate and if dedicated HBAs or sharing of HBAs between hosts should be considered (VIO/NPIV).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>
          On
          <b>Linux,</b>
          these values represent the sum of all block devices named hd[a-z]+ (IDE) and sd[a-z]+ (SCSI)
        </p>
        <p>
          On
          <b>AIX,</b>
          these values represent the sum of all block devices that are NOT named cd[0-9]+, dac[0-9]+, hdiskpower[0-9]+ or vpath[0-9]+
        </p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 37</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Receive + Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the combined network throughput of all the interfaces in KB/s (received and sent) for all hosts on the server in a "stacked area" view.  These interfaces can be removed from or added to the chart based upon the legend check boxes on the left side of the chart (zoom in).  Loopback network I/O is not included.  This frame view can be used to determine which hosts have the highest throughput and if dedicated NICs or sharing of NICs between hosts should be considered (VIO).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 38</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Receive Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual network RECEIVE throughput in KB/s of all the hosts on the server in a "stacked area" view.  This is indicative of the actual data rate transferring through the network in READ operations at the given time period.  This frame view can be used to determine which hosts have the highest throughput and if dedicated NICs or sharing of NICs between hosts should be considered (VIO).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 39</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual network SEND throughput in KB/s of all the hosts on the server in a "stacked area" view.  This is indicative of the actual data rate transferring through the network in WRITE operations at the given time period.  This frame view can be used to determine which hosts have the highest throughput and if dedicated NICs or sharing of NICs between hosts should be considered (VIO).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 40</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Packet Receive + Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the combined network packets throughput (received and sent) of all the interfaces for all hosts on the server in a "stacked area" view.  These interfaces can be removed from or added to the chart based upon the radio buttons at the bottom of the chart (zoom in).  Loopback network I/O is not included.  This frame view can be used to determine which hosts have the highest throughput and if dedicated NICs or sharing of NICs between hosts should be considered (VIO).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 41</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Packet Receive Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual network RECEIVE packets in packets/s of all the hosts on the server in a "stacked area" view.  This is indicative of the actual packet rate transferring through the network in READ operations at the given time period.  This frame view can be used to determine which hosts have the highest throughput and if dedicated NICs or sharing of NICs between hosts should be considered (VIO).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 42</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Packet Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual network SEND packets in packets/s of all the hosts on the server in a "stacked area" view.  This is indicative of the actual packet rate transferring through the network in WRITE operations at the given time period.  This frame view can be used to determine which hosts have the highest throughput and if dedicated NICs or sharing of NICs between hosts should be considered (VIO).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 44</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host System Page-Ins
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart displays the <b>Page Space Page-Ins</b> (paging) rate per second from paging space of all hosts on the server in a "non-stacked line" view.  This is a quick view of all LPARs on the server to quickly identify host paging, symptomatic of a memory problem.</p>
        <p>If <b>Page-Ins</b> and <b>Page-Outs</b> are consistently occurring, this may indicate memory thrashing.  The <b>Memory, VMM</b> and <b>Paging</b> charts for the problem LPAR may be of help.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 45</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host System Page-Outs
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart displays the <b>Page Space Page-Outs</b> (paging) rate per second to paging space of all hosts on the server in a "non-stacked line" view.  This is a quick view of all LPARs on the server to quickly identify host paging, symptomatic of a memory problem.</p>
        <p>If <b>Page-Ins</b> and <b>Page-Outs</b> are consistently occurring, this may indicate memory thrashing.  The <b>Memory, VMM</b> and <b>Paging</b> charts for the problem LPAR may be of help.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 46</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Memory (Scan / Free Ratio)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart displays the number of memory pages scanned as a ratio to the number of memory pages freed for all hosts on the server in a "non-stacked line" view.  This is a quick view of all LPARs on the server to quickly identify hosts possibly having memory problems.</p>
        <p>When the memory free-list is low and processes make requests for memory, the kernel spends CPU time scanning for memory pages that can be freed.  If the number of pages freed is too small, the kernel spends more CPU time scanning for pages to be freed.</p>
        <p>If the Scan to Free Ratio is greater than 4 on average, then memory is very active (over 75% utilized), which could be a sign of needing more memory, memory is over committed or tuning is required.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <ul>
          <li>Things to Check in the Host:</li>
          <ul class='nested'>
            <li>"System Paging" chart for thrashing.</li>
            <li>"Real Memory" and "Memory Use" charts for the past month to see if memory allocations were reduced.</li>
            <li>DB memory buffers may have been increased or additional DB instances were started.</li>
            <li>AVA HEAP/memory was increased in applications.</li>
            <li>New applications were added using more memory memory.</li>
            <li>Memory leaks, often with new applications or JAVA applications.</li>
            <li>"Large Page Support" was activated and over allocated.</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 47</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Network Read/Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'></div>
      <div class='definitions'>
        <p>This chart shows the RECEIVE and SEND network throughput of all the interfaces in KB/s in a "stacked area" view.  This chart can be used to determine which interface has the highest throughput and whether dedicated NICs should be considered.  If an LPAR, sharing of NICs using VIO or IVE may be considered.  Link aggregation or upgrading the NICs to a faster interface may also be considered.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 48</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Network Read/Write Packets
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the network packets of all the interfaces in packets/second for both receives and sends in a "stacked area" view.  These interfaces can be removed from or added to the chart based upon the radio buttons at the left of the chart (zoom in).  This host chart can be used to determine which interface has the highest throughput and whether dedicated NICs should be considered.  If an LPAR, sharing of NICs using VIO or IVE may be considered.  Link aggregation or upgrading the NICs to a faster interface may also be considered.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 49</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Run Queue
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>
          This chart displays the <b>Run Queue</b> of all hosts on the server in a "non-stacked
          line" view.  This is a quick view of all LPARs on the server.  The Run Queue indicates
          the number of active running processes on the host that are presently consuming
          resources.
        </p>
        <p>
          For example, if the process "httpd" is running, but not being accessed, it will
          not be 'counted' in the run queue. In this case, the httpd process is sleeping,
          waiting for the next interrupt for it to begin processing. When an interrupt occurs,
          the httpd process will be moved to the run queue, and the run queue number will
          be increased by 1.
        </p>
        <p>
          There are several opinions and rule-of-thumbs on the run queue number, but it depends
          on your particular workload and service level objectives. If 'response time' is
          most important, you may want it no higher than 1 to 2 times the number of CPUs
          (virtual or real) allocated to the Host. If 'job throughput' is important, greater
          than 3 to 4 times times the number of CPUs may be sufficient to keep the processors busy
          especially with SMT On. A high run queue may be a sign of an overcommitted system, CPU intensive
          processes hogging the queue or a user/job-scheduling package or script mistakenly
          running too many processes at once. <b>Context Switch/System Calls</b>, <b>Processes
          Forks/EXECs</b> and the <b>CPU Utilization</b> charts may be of help.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 50</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the <b>Disk Service Times</b> in milliseconds (ms) from/to each disk of the host.  You can quickly identify disks with poor service times.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Caution:</p>
        <p>If you observe a disk with high service times, first verify the suspect disks "time period" against the "Disk Transfers" chart to ensure there are greater than 5 to 10 transfers per second (TPS) of activity.  Sometimes with minimal to 0 TPS, the service time shown by the OS is high and not meaningful.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 70</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Tape Read/Write Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual tape data rate (reads and writes) of the LPAR in question in MB/s.  This is indicative of the actual data rate transferring to/from the TAPE in both read and write operations, and the end value that is displayed is the combined rate of both operations at the given time period.</p>
        <p>This is helpful to understand when there are READ and WRITE operations, to determine when either of those activities is "abnormal" and should NOT be occurring.</p>
        <p>Selecting this chart allows a user to select/de-select certain tape devices to drill down on specific workload.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 71</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Tape Read Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the amount of data READ in MB/s from each tape device in the LPAR.  You can quickly identify heavy tape READs or if there is an even distribution of READs across the tapes.  This "stacked area" view allows you to quickly see the total tape READs in MB/s for the host.</p>
        <p>Selecting this chart allows a user to select/de-select certain tape devices to drill down on specific workload.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 72</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Tape Write Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the amount of data WRITTEN in MB/s to each tape device in the LPAR.  You can quickly identify heavy tape WRITEs or if there is an even distribution of WRITEs across the tapes.  This "stacked area" view allows you to quickly see the total tape WRITEs in MB/s for the host.</p>
        <p>Selecting this chart allows a user to select/de-select certain Tape devices to drill down on specific workload.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 73</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Tape Reads Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the amount of data READ in MB/s from each system with tape devices for the hosts placed into your Frame (or Virtual Frame).  You can quickly identify systems with heavy tape READs or if there is an even distribution of READs across the hosts.  This is a "stacked area" view to quickly see the total tape READs in MB/s for the hosts placed into your Frame (or Virtual Frame).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Selecting this chart allows a user to select/de-select certain systems to drill down on specific workload.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 74</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Tape Writes Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the amount of data WRITTEN in MB/s to each system with tape devices for the hosts placed into your Frame (or Virtual Frame).  You can quickly identify systems with heavy tape WRITEs or if there is an even distribution of writes across the hosts.  This is a "stacked area" view to quickly see the total tape WRITEs in MB/s for the hosts placed into your Frame (or Virtual Frame).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Selecting this chart allows a user to select/de-select certain systems to drill down on specific workload.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 77</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Shared Usage + Dedicated Allocation
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>For <b>Shared LPARs</b> (capped or uncapped), this chart shows the total active CPU units on the managed system, as well as the actual physical CPU units consumed by the active LPARs in a stacked area view.  For <b>Dedicated LPARs</b>, either capped or donating, this chart shows the CPU units allocated to the LPARs, regardless of whether or not they are actually used.  Depending upon the physical architecture (i.e., Power5, Power6, Power7, etc.), the CPUs are defined to an LPAR in one of the following Types-Modes:</p>
      </div>
      <div class='definitions'>
        <ul>
          <li><b>Shared-Uncapped</b> Share with others; can go above Entitlement</li>
          <li><b>Shared-Capped</b> Share with others; CANNOT go above Entitlement</li>
          <li><b>Dedicated-Uncapped</b> Exclusive CPUs and NO SHARING unused CPU with others</li>
          <li><b>Dedicated-Donating</b> Guaranteed CPUs and SHARE/DONATE unused CPU with others.</li>
        </ul>
      </div>
      <div class='notes'>
        <p>Note: Refer to IBM documentation for more info.</p>
        <p>This physical server view can be used to determine if more CPUs are needed (possibly using CUoD), or which LPARs are the largest consumers of CPU resources.  This chart can be used to determine if an LPAR requires tuning, or if an adjustment to an LPAR's Weight, Entitlement, Capping or the number of Virtual Processors is necessary.  The Dedicated-Capped Allocation + Donated/Shared Usage chart should be reviewed to identify the actual CPU units consumed by a "Dedicated-Donating" LPAR.  "Dedicated-Capped" LPARs with low CPU usage and over-allocated CPUs may be reclaimed and shared with others.</p>
        <p>Since an LPAR's type and mode may have changed over the time duration selected for viewing, the additional charts referenced above should be reviewed for a thorough understanding.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 78</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Dedicated Capped Allocation + Donated/Shared Usage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>For <b>Shared</b> and <b>Dedicated-Donating LPARs</b>, this chart shows the total active CPU units on the managed system, as well as the actual physical CPU units consumed by the active LPARs in a stacked area view.  For <b>Dedicated-Capped LPARs</b>, this chart shows the CPU units allocated to the LPARs regardless of whether or not they are actually used.  Depending upon the physical architecture (i.e., Power5, Power6, Power7, etc.), the CPUs are defined to an LPAR in one of the following Types-Modes:</p>
      </div>
      <div class='definitions'>
        <ul>
          <li><b>Shared-Uncapped</b> Share with others; can go above Entitlement</li>
          <li><b>Shared-Capped</b> Share with others; CANNOT go above Entitlement</li>
          <li><b>Dedicated-Uncapped</b> Exclusive CPUs and NO SHARING unused CPU with others</li>
          <li><b>Dedicated-Donating</b> Guaranteed CPUs and SHARE/DONATE unused CPU with others.</li>
        </ul>
      </div>
      <div class='notes'>
        <p>Note: Refer to IBM documentation for more info</p>
        <p>This physical server view can be used to determine if more CPUs are needed (possibly using CUoD), or which LPARs are the largest consumers of CPU resources.  Tuning may be required inside an LPAR, or an adjustment to an LPAR's Weight, Entitlement, Capping or the number of Virtual Processors may be necessary.  "Dedicated-Capped" LPARs with low CPU usage and over-allocated CPUs may be reclaimed and shared with others.</p>
        <p>Since an LPAR's type and mode may have changed over the time duration selected for viewing, the additional charts referenced above should be reviewed for a thorough understanding.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 81</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Large Page Memory (Pages)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart displays the number of pages <b>Used and Allocated for Huge/Large Pages</b> as designated by the System Administrator.  Using this feature can yield performance throughput improvements to applications "authorized" to use the Huge/Large Page Memory.</p>
        <p>Great care should be taken to fully understand how Huge/Large Page Memory works as it can cause severe memory constraints, paging and memory thrashing if used incorrectly.  For example, if the chart shows 50 pages of Allocated Memory but 0 Used, then 50 pages of "Free" memory exist, though it does not show up on the Free Memory list, and it is NOT for use by general applications.  The system could incur system paging and poor response time because of a shortage of memory, while these 50 pages are reserved, but unavailable to unauthorized applications.</p>
        <p>You can quickly identify if the Huge/Large Page Memory is over or under allocated.  If the trend shows continual free memory (over allocation = Allocated - Used), consideration should be given to reducing the allocation, giving memory back for general use.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 82</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Memory Use
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the allocation of real memory in the host. This is displayed as a combination of the following four elements:</p>
      </div>
      <div class='definitions'>
        <ul>
          <li><b>Process</b></li>
          <li><b>Buffers</b> - inodes</li>
          <li><b>Cached</b> - filesystem and disk cache memory</li>
          <li><b>Allocated</b> - Total memory detected and configured for use by the OS</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 83</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU Consumed
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <div class='definitions'>
          <ul>
            <li><b># of Virtual CPUs</b> represents the number of physical processors (cores) presented/assigned to this host.  If Hyper-Threading (HT) is enabled, the <b># of Logical CPUs</b> in the <b>CPU (Logical) Utilization</b> chart will be greater than the <b># of Virtual CPUs</b>.  Hyper-threading, also known as Simultaneous Multi-Threading (SMT), is the ability of a single physical processor (core) to concurrently process multiple program threads from the operating system.  Two or more program threads can run on one physical processor (core) at the same time.  Hyper-threading is a good choice when overall throughput is more important than the throughput of an individual thread.  For example, Web and database servers are good candidates.</li>
          </ul>
          <ul>
            <li><b>Physical CPU Consumed</b> is derived from the sum of (User%+System%) multiplied by "# of Virtual CPUs".  This is intended to represent the amount of physical processing units consumed (used) by this HOST.</li>
          </ul>
        </div>
        <div class='notes'>
          <ul>
            CAUTION: Windows 2003 without <b>HOTFIX KB932370</b> cannot detect Hyper-Threading, potentially causing the "# of Virtual CPUs" and "CPU Consumed" values to report a higher value IF Hyper-Threading is enabled.
          </ul>
          <ul>
            For Example: The host has 8 Virtual CPUs (cores) with Hyper-Threading ENABLED, Windows shows 16 CPUs (LPs).  50% utilization would show 8 Physical CPUs consumed out of 16 (LPs) when in fact our consumption would only be 4 physical CPUs (50% of 8 VPs).  This scenario is resolved with the HOTFIX noted above.
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 84</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end read and write throughput</b> rates for the cluster.  Front-end reads and writes are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 85</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rates of <b>Front-end read and write operations</b> issued to the cluster.  Front-end transfers are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 86</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Service Times (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end Service Time</b>, or response time, for reads and writes from/to the cluster.  Front-end service times indicate how quickly the SVC or Storwize V7000 is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 87</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end read and write throughput</b> rates for the cluster.  Back-end reads and writes are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 88</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Transfer (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rates of <b>Back-end read and write operations</b> issued by the cluster.  Back-end transfers are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 89</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Service Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Cluster Service Time</b> or response time for back-end reads and writes initiated by the cluster.  Back-end service times indicate how quickly a back-end storage array is responding to requests from the SVC or Storwize V7000.
      </div>
      <div class='notes'>
        Note that service times for INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will only display service times for EXTERNAL drives and zeros for internal drives with downlevel SVC code.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 91</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Read Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end read throughput</b> rate for each I/O group.  Front-end reads are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 92</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end write throughput</b> rate for each I/O group.  Front-end writes are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 93</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Read Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Front-end read operations</b> issued to each I/O group.  Front-end transfers are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 94</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Front-end write operations</b> issued to each I/O group.  Front-end transfers are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 95</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Read Service Times (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the front-end service time, or response time, for reads from each I/O group.  Front-end service times indicate how quickly the SVC or Storwize V7000 is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 96</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Service Times (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the front-end service time, or response time, for writes to each I/O group.  Front-end service times indicate how quickly the SVC or Storwize V7000 is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 97</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Read Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end read throughput</b> rate for each I/O group.  Back-end reads are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 98</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end write throughput</b> rate for each I/O group.  Back-end writes are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 99</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Read Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Back-end read operations</b> issued by each I/O group.  Back-end transfers are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 100</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Back-end write operations</b> issued by each I/O group.  Back-end transfers are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 101</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Read Service Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service time, or response time, for back-end reads initiated by each I/O group.  Back-end service times indicate how quickly a back-end storage array is responding to requests from the SVC or Storwize V7000.
      </div>
      <div class='notes'>
        Note that service times for INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will only display service times for EXTERNAL storage arrays and zeros for internal drives with downlevel SVC code.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 102</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Service Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service time, or response time, for back-end writes initiated by each I/O group.  Back-end service times indicate how quickly a back-end storage array is responding to requests from the SVC or Storwize V7000.
      </div>
      <div class='notes'>
        Note that service times for INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will only display service times for EXTERNAL storage arrays and zeros for internal drives with downlevel SVC code.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 104</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end read throughput</b> rate for each SVC or Storwize V7000 node.  Front-end reads are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 105</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end write throughput</b> rate for each SVC or Storwize V7000 node.  Front-end writes are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 106</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>front-end read operations</b> issued to each SVC or Storwize V7000 node.  Front-end transfers are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 107</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Front-end write operations</b> issued to each SVC or Storwize V7000 node.  Front-end transfers are those initiated by a host, directed at virtual disks or volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 108</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Service Times (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the front-end service time, or response time, for reads from each SVC or Storwize V7000 node.  Front-end service times indicate how quickly the SVC or Storwize V7000 is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 109</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Service Times (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the front-end service time, or response time, for writes to each SVC or Storwize V7000 node.  Front-end service times indicate how quickly the SVC or Storwize V7000 is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 110</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end read throughput</b> rate for each SVC or Storwize V7000 node.  Back-end reads are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 111</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end write throughput</b> rate for each SVC or Storwize V7000 node.  Back-end writes are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 112</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Back-end read operations</b> issued by each SVC or Storwize V7000 node.  Back-end transfers are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 113</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Back-end write operations</b> issued by each SVC or Storwize V7000 node.  Back-end transfers are those initiated by the SVC or Storwize V7000, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 114</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Service Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service time, or response time, for back-end reads initiated by each SVC or Storwize V7000 node.  Back-end service times indicate how quickly a back-end storage array is responding to requests from the SVC or Storwize V7000.
      </div>
      <div class='notes'>
        Note that service times for INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will only display service times for EXTERNAL storage arrays and zeros for internal drives with downlevel SVC code.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 115</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Service Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service time, or response time, for back-end writes initiated by each SVC or Storwize V7000 node.  Back-end service times indicate how quickly a back-end storage array is responding to requests from the SVC or Storwize V7000.
      </div>
      <div class='notes'>
        Note that service times for INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will only display service times for EXTERNAL storage arrays and zeros for internal drives with downlevel SVC code.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 116</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node CPU Percent Busy
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of time the SVC or Storwize V7000's CPUs are busy performing work not related to real-time compression. Note that this is a percentage of the CPU cores dedicated to non-compression duties, and can therefore range from 0% to 100% independent of Node CPU Percent Compression, which is displayed in a separate chart.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 117</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Read Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end read throughput</b> rate from virtual disks or volumes in each managed disk group or storage pool.  Front-end reads are those initiated by a host, directed at virtual disks or volumes that reside in a given managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 118</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Write Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end write throughput</b> rate to virtual disks or volumes in each managed disk group or storage pool.  Front-end writes are those initiated by a host, directed at virtual disks or volumes that reside in a given managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 119</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Read Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Front-end read operations</b> issued to virtual disks or volumes in each managed disk group or storage pool.  Front-end transfers are those initiated by a host, directed at virtual disks or volumes that reside in a given managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 120</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Write Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Front-end write operations</b> issued to virtual disks or volumes in each managed disk group or storage pool.  Front-end transfers are those initiated by a host, directed at virtual disks or volumes that reside in a given managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 121</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Read Service Times (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end service time</b>, or response time, for reads from each managed disk group or storage pool.  Front-end service times indicate how quickly the SVC or Storwize V7000 is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 122</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Write Service Times (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Front-end service time</b>, or response time, for writes to each managed disk group or storage pool.  Front-end service times indicate how quickly the SVC or Storwize V7000 is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 123</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Read Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end read throughput</b> rate from each managed disk group or storage pool.  Back-end reads are those initiated by the SVC or Storwize V7000, directed at the back-end storage array(s) comprising a managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 124</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Write Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end write throughput</b> rate to each managed disk group or storage pool.  Back-end writes are those initiated by the SVC or Storwize V7000, directed at the back-end storage array(s) comprising a managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 125</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Read Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Back-end read operations</b> issued to each managed disk group or storage pool.  Back-end transfers are those initiated by the SVC or Storwize V7000 to the back-end storage array(s) comprising a managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 126</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Write Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>Back-end write operations</b> issued to each managed disk group or storage pool.  Back-end transfers are those initiated by the SVC or Storwize V7000 to the back-end storage array(s) comprising a managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 127</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Read Service Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end service time</b>, or response time, for reads from each managed disk group or storage pool.  Back-end service times indicate how quickly a back-end storage array is responding to requests from the SVC or Storwize V7000.
      </div>
      <div class='notes'>
        Service times for managed disks comprised of INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will display zeros for internal managed disk groups or storage pools with downlevel SVC code.  If a managed disk group or storage pool contains both external and internal managed disks, only service times for the EXTERNAL managed disks are included in this chart.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 128</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Write Service Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>Back-end service time</b>, or response time, for writes to each managed disk group or storage pool.  Back-end service times indicate how quickly a back-end storage array is responding to requests from the SVC or Storwize V7000.
      </div>
      <div class='notes'>
        Service times for managed disks comprised of INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will display zeros for internal managed disk groups or storage pools with downlevel SVC code.
        If a managed disk group or storage pool contains both external and internal managed disks, only service times for the EXTERNAL managed disks are included in this chart.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 130</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>READ</b> throughput rate from each managed disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 131</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>WRITE</b> throughput rate to each managed disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 132</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>READ</b> operations issued to each managed disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 133</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>WRITE</b> operations issued to each managed disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 134</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Read Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>READ service times</b>, or response time, from each managed disk.
      </div>
      <div class='notes'>
        Service times for managed disks comprised of INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will only display service times EXTERNAL managed disks and zeros for internal managed disks with downlevel SVC code.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 135</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Write Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>WRITE service times</b>, or response time, to each managed disk.
      </div>
      <div class='notes'>
        Service times for managed disks comprised of INTERNAL drives are only available for SVCs with code level <b>6.3.0.1 or higher</b>.  This chart will only display service times EXTERNAL managed disks and zeros for internal managed disks with downlevel SVC code.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 136</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>READ throughput</b> rate from each virtual disk or volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 137</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>WRITE throughput</b> rate to each virtual disk or volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 138</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>READ</b> operations issued to each virtual disk or volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 139</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>WRITE service times, or response time, to each virtual disk or volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 140</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Read Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>READ service times</b>, or response time, from each virtual disk or volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 141</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Write Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>WRITE</b> operations issued to each virtual disk or volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 142</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU (Entitlement) Utilization
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the percentage of entitled capacity consumed.  This is only applicable to shared LPARs.  The entitled capacity percentage (%) can exceed 100% for shared uncapped LPARs.  This is a breakdown of the CPU consumed relative to the entitlement by the host.  It is very important to understand this is the % breakdown of the CPU Consumed towards 100% of the Entitlement.  This will show what % of CPU consumption is spent in User, System, IO Wait or Idle processing.  Typically User+Sys+IOwait+Idle = 100%.  But with VPs, SMT4 and Power7, some idle cycles are consumed and reported as Idle within the CPU consumed cycles.</p>
        <p>It should also be noted for dedicated capped LPARs, the entitlement is equal to the VPs and this chart will not reflect more than 100%, and should parallel the VP Utilization chart.</p>
      </div>
      <div class='definitions'>
        <ul>
          <li><b>User</b> represents the percentage of time the host spent in user mode relative to entitlement.  Programs running in USER mode don't have access to the kernel or its data segments, except indirectly through system calls.  A program in this mode can only affect its own execution environment and runs in the processor-unprivileged state.</li>
          <li><b>System</b> represents the percentage of time the host spent in system mode relative to entitlement.  Programs that run in system mode include interrupt handlers, base kernel and kernel extensions (including device drivers).  Programs running in system mode have read/write access to global kernel address space and to the kernel data in the process private segment when running in the process context.  Context switch time, system calls, device interrupts, NFS I/O and anything else being processed by the kernel is considered system time.</li>
          <li><b>Wait</b> represents the percentage of time the host spent idle with pending disk I/O, relative to entitlement, to not only local, but also NFS-mounted disks.</li>
          <li><b>Idle</b> represents the percentage of time the host spent consuming Idle cycles (Used) relative to entitlement.</li>
        </ul>
      </div>
      <div class='notes'>
        <p>Caution:</p>
        <p>Traditionally CPU utilization reflects the sum of user+system+IOwait+idle which is 100%.  But in a virtual environment, often Wait and Idle processing consume CPU cycles and are considered as part of the Physical CPU Consumption used by the virtual host, independent of the unused (traditional idle) cycles.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 143</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU (Virtual/Core) Utilization
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the <b>Virtual Processors (VP) CPU utilization</b> (%Busy) breakdown of the CPU consumed by the host.  It is very important to understand this is the % breakdown of the CPU consumed towards 100% of the VP's.  This will show what % of CPU consumption is spent in User, System, IO Wait or Idle processing.  Typically User+Sys+IOwait+Idle = 100%.  But with VPs, SMT4 and Power7, some idle cycles are consumed and reported as Idle within the CPU consumed cycles.  The unused VP CPU capacity available for additional consumption (uncapped) is shown relative to 100% in this chart.</p>
        <p>It should also be noted where the "CPU (Logical) Utilization" chart is not a reliable reflection of the real CPU usage because of skewing caused by hyper-threading, this "CPU Virtual" Utilization chart reflects the real CPU consumed and available.</p>
      </div>
      <div class='definitions'>
        <ul>
          <li><b>User</b> represents the percentage of time the host's VPs spent in user mode.  Programs running in USER mode don't have access to the kernel or its data segments, except indirectly through system calls.  A program in this mode can only affect its own execution environment and runs in the processor-unprivileged state.</li>
          <li><b>System</b> represents the percentage of time the host's VPs spent in system mode.  Programs that run in system mode include interrupt handlers, base kernel and kernel extensions (including device drivers).  Programs running in system mode have read/write access to global kernel address space and to the kernel data in the process private segment when running in the process context.  Context switch time, system calls, device interrupts, NFS I/O and anything else being processed by the kernel is considered system time.</li>
          <li><b>Wait</b> represents the percentage of time the VPs spent idle with pending disk I/O to not only local, but also NFS-mounted disks.</li>
          <li><b>Idle</b> represents the percentage of time the VPs spent consuming Idle cycles (Used).</li>
        </ul>
      </div>
      <div class='notes'>
        <p>Caution:</p>
        <p>Traditionally CPU utilization reflects the sum of user+system+IOwait+idle which is 100%.  But in a virtual environment, often wait and idle processing consume CPU cycles and are considered as part of the Physical CPU Consumption used by the virtual host, independent of the unused (traditional idle) cycles.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 144</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host CPU (Entitlement) Percent Consumed
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the percentage of entitled capacity consumed by each LPAR.  This is a QUICK view of all hosts on the server to determine if any host is continually running above its entitlement (>100%).  If it is a production host and the average consumed is higher than the entitlement (>100%), the production host entitlement should be increased to avoid hypervisor overhead.  Often non-production hosts are set to a low entitlement to allow more CPU to be in the shared pools for use by production hosts during high demand periods.</p>
        <p>For this high level summary, the entitlement % of each host is calculated as User+System+IOwait+Idle.</p>
        <p>The HELP for CPU (Entitlement) Utilization of the individual host should be referenced for a complete description.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Caution: This is a percentage of consumed CPU proportional to the hosts entitlement setting, and NOT a percentage of CPU proportional to the # of Virtual Processors (VPs).</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 145</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host CPU (Virtual/Core) Percent Busy
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the <b>Virtual Processors (VP) CPU utilization</b> (%Busy) breakdown of the CPU consumed by each LPAR.  This is a QUICK view of all hosts on the server to determine if any host is continually using a high percentage of their VPs.  If a production host and the % is greater than 80%, one may want to consider adding an additional VP to the host or investigate the high CPU utilization within the host.</p>
        <p>For this high level summary, the CPU percentage of each host is calculated as User+System (IOwait and Idle are excluded).</p>
        <p>The HELP for the CPU (Virtual/Core) Utilization of the individual host should be referenced for a complete description.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Caution: IOwait and Idle are NOT included in this high level view.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 146</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of <b>Disk Read Transfers</b> per second (IO/s) from each disk of the host.  You can quickly identify heavy read disks or if there is an even distribution of reads across the disks.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 147</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of <b>Disk Write Transfers</b> per second (IO/s) to each disk of the host.  You can quickly identify heavy write disks or if there is an even distribution of writes across the disks.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 148</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Read Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the <b>Disk Read Service Times</b> in milliseconds (ms) from each disk of the host.  You can quickly identify disks with poor service times.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Caution:</p>
        <p>If you observe a disk with high service times, first verify the suspect disks time period against the "Disk Transfers" chart to ensure there are greater than 5 to 10 transfers per second (TPS) of activity.  Sometimes with minimal to 0 TPS, the service time shown by the OS is high and not meaningful.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 149</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Write Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the <b>Disk Write Service Times</b> in milliseconds (ms) to each disk of the host.  You can quickly identify disks with poor service times.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Caution:</p>
        <p>If you observe a disk with high service times, first verify the suspect disks time period against the "Disk Transfers" chart to ensure there are greater than 5 to 10 transfers per second (TPS) of activity.  Sometimes with minimal to 0 TPS, the service time shown by the OS is high and not meaningful.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 150</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Read Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average size (blocksize) of the <b>Disk Read Transfers</b> in KB per second for each disk of the host.  You can quickly identify large vs. small transfer sizes.  Large transfer sizes often indicate sequential processing workloads while small transfer sizes often indicate random transactional workloads.  This is a "non-stacked line" view, which quickly allows the large size transfers to stand above the small size transfers.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 151</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Write Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average size (blocksize) of the <b>Disk Write Transfers</b> in KB per second for each disk of the host.  You can quickly identify large vs. small transfer sizes.  Large transfer sizes often indicate sequential processing workloads while small transfer sizes often indicate random transactional workloads.  This is a "non-stacked line" view, which quickly allows the large size transfers to stand above the small size transfers.
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 152</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Memory Use
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the allocation of real memory in the host.  This is displayed as a combination of the following four elements:
      </div>
      <div class='definitions'>
        <ul>
          <li><b>Allocated</b></li>
          <ul class='secondary-list'>
            <li>Total memory detected and configured for use by the OS.</li>
          </ul>
          <li><b>System/Pool Nonpaged</b></li>
          <ul class='secondary-list'>
            <li>Windows <b>perfmon</b> Memory\\Pool Nonpaged Bytes is the size in bytes of the nonpaged pool, an area of system memory (physical memory used by the operating system) for objects that cannot be written to disk, but must remain in physical memory as long as they are allocated.  Memory\\Pool Nonpaged Bytes is calculated differently than Process\\Pool Nonpaged Bytes, so it might not equal Process\\Pool Nonpaged Bytes\\_Total.</li>
          </ul>
          <li><b>Process/Working Set</b></li>
          <ul class='secondary-list'>
            <li>Windows <b>perfmon</b> Process(_Total)\Working Set is the current size in bytes of the Working Set of all processes.  The Working Set is the set of memory pages touched recently by the threads in the process.  If free memory in the computer is above a threshold, pages are left in the Working Set of a process even if they are not in use.  When free memory falls below a threshold, pages are trimmed from Working Sets.  If they are needed they will then be soft-faulted back into the Working Set before leaving main memory.</li>
          </ul>
          <li><b>Cached</b></li>
          <ul class='secondary-list'>
            <li>Windows <b>perfmon</b> Memory\\Cache Bytes is the sum of the Memory\\System Cache Resident Bytes, Memory\\System Driver Resident Bytes, Memory\\System Code Resident Bytes, and Memory\\Pool Paged Resident Bytes counters.</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 153</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Port Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the sum throughput of traffic SENT and RECEIVED by all ports on all nodes of the SVC or Storwize V7000 cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 154</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Port Received Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p></p>
        This chart shows the sum throughput of traffic RECEIVED by all ports on both nodes of the SVC or Storwize V7000 I/O group.
        <ul>
          <p>Traffic received on a given port can include multiple types of traffic including:</p>
          <ul class='nested'>
            <li>Reads from back-end disk</li>
            <li>Writes from hosts</li>
            <li>INTRA-Cluster communications</li>
            <li>INTER-Cluster communications</li>
          </ul>
          <ul></ul>
        </ul>
        <p>The default <b>Stacked Area</b> view for this chart provides an easy way to view the balance of traffic over I/O groups.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 155</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Port Sent Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>
          This chart shows the sum throughput of traffic SENT by all ports on both nodes of the SVC or Storwize V7000 I/O group.
        </p>
        <ul>
          <p>Traffic sent on a given port can include multiple types of traffic including:</p>
          <ul class='nested'>
            <li>Writes to back-end disk</li>
            <li>Reads from hosts</li>
            <li>INTRA-Cluster communications</li>
            <li>INTER-Cluster communications</li>
          </ul>
          <ul></ul>
        </ul>
        <p>The default <b>Stacked Area</b> view for this chart provides an easy way to view the balance of traffic over I/O groups.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 156</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Port Received Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p></p>
        This chart shows the sum throughput of traffic RECEIVED by all ports on the SVC or Storwize V7000 node.
        <ul>
          <p>Traffic received on a given port can include multiple types of traffic including:</p>
          <ul class='nested'>
            <li>Reads from back-end disk</li>
            <li>Writes from hosts</li>
            <li>INTRA-Cluster communications</li>
            <li>INTER-Cluster communications</li>
          </ul>
          <ul></ul>
        </ul>
        <p>The default <b>Stacked Area</b> view for this chart provides an easy way to view the balance of traffic over multiple nodes.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 157</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Port Sent Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>
          This chart shows the sum throughput of traffic SENT by all ports on the SVC or Storwize V7000 node.
        </p>
        <ul>
          <p>Traffic sent on a given port can include multiple types of traffic including:</p>
          <ul class='nested'>
            <li>Writes to back-end disk</li>
            <li>Reads to hosts</li>
            <li>INTRA-Cluster communications</li>
            <li>INTER-Cluster communications</li>
          </ul>
          <ul></ul>
        </ul>
        <p>The default <b>Stacked Area</b> view for this chart provides an easy way to view the balance of traffic over multiple nodes.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 158</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Received Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p></p>
        This chart shows the throughput of traffic RECEIVED by the SVC or Storwize V7000 port.
        <ul>
          <p>Traffic received on a given port can include multiple types of traffic including:</p>
          <ul class='nested'>
            <li>Reads from back-end disk</li>
            <li>Writes from hosts</li>
            <li>INTRA-Cluster communications</li>
            <li>INTER-Cluster communications</li>
          </ul>
          <ul></ul>
        </ul>
        <p>The default <b>Line</b> view for this chart provides an easy way to discern if any port is approaching its theoretical maximum.</p>
        <p>Selecting the <b>Stacked Area</b> view for this chart provides an easy way to view the balance of traffic over multiple ports.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 159</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Sent Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p></p>
        This chart shows the throughput of traffic SENT by the SVC or Storwize V7000 port.
        <ul>
          <p>Traffic sent on a given port can include multiple types of traffic including:</p>
          <ul class='nested'>
            <li>Writes to back-end disk</li>
            <li>Reads to hosts</li>
            <li>INTRA-Cluster communications</li>
            <li>INTER-Cluster communications</li>
          </ul>
          <ul></ul>
        </ul>
        <p>The default <b>Line</b> view for this chart provides an easy way to discern if any port is approaching its theoretical maximum.</p>
        <p>Selecting the <b>Stacked Area</b> view for this chart provides an easy way to view the balance of traffic over multiple ports.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 160</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port to Host Received Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the throughput of host traffic RECEIVED by the SVC or Storwize V7000 port.  This chart includes ONLY traffic received from hosts.  Other traffic is not included in this metric.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 161</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port to Host Sent Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the throughput of host traffic SENT by the SVC or Storwize V7000 port.  This chart includes ONLY traffic sent to hosts.  Other traffic is not included in this metric.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 162</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port to Disk Received Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the throughput of disk traffic RECEIVED by the SVC or Storwize V7000 port.  This chart includes ONLY traffic received from back-end disk systems.  Other traffic is not included in this metric.
      </div>
      <div class='notes'>
        If your cluster utilizes IBM Storwize family products as back-end managed disks (mdisks), this chart may be inaccurate. Due to the way SVC identifies Storwize managed disks, I/O to Storwize family managed disks may be reported as Port to Remote node I/O.  If your cluster uses Storwize family managed disks, Port to Disk charts may be under-reporting throughput, and Port to Remote charts may be over-reporting throughput by an equal amount. Please see the Cluster Replication Throughput chart for a more accurate representation of total replication throughput.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 163</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port to Disk Sent Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the throughput of disk traffic SENT by the SVC or Storwize V7000 port.  This chart includes ONLY traffic sent to back-end disk systems.  Other traffic is not included in this metric.
      </div>
      <div class='notes'>
        If your cluster utilizes IBM Storwize family products as back-end managed disks (mdisks), this chart may be inaccurate. Due to the way SVC identifies Storwize managed disks, I/O to Storwize family managed disks may be reported as Port to Remote node I/O.  If your cluster uses Storwize family managed disks, Port to Disk charts may be under-reporting throughput, and Port to Remote charts may be over-reporting throughput by an equal amount. Please see the Cluster Replication Throughput chart for a more accurate representation of total replication throughput.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 164</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port to Local Received Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p></p>
        This chart shows the throughput of traffic RECEIVED by the SVC or Storwize V7000 port from other nodes in the same cluster.
        <ul>
          <p>This traffic includes:</p>
          <ul class='nested'>
            <li>INTRA-Cluster communication traffic</li>
            <li>Cache mirroring traffic</li>
            <li>I/O to and from solid state disks housed in other nodes</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 165</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port to Local Sent Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p></p>
        This chart shows the throughput of traffic SENT by the SVC or Storwize V7000 port to other nodes in the same cluster.
        <ul>
          <p>This traffic includes:</p>
          <ul class='nested'>
            <li>INTRA-Cluster communication traffic</li>
            <li>Cache mirroring traffic</li>
            <li>I/O to and from solid state disks housed in other nodes</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 166</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port to Remote Received Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p></p>
        This chart shows the throughput of traffic RECEIVED by the SVC or Storwize V7000 port from other nodes in <b>REMOTE</b> clusters.
        <ul>
          <p>This traffic includes:</p>
          <ul class='nested'>
            <li>Global Mirror replication traffic</li>
            <li>Metro Mirror replication traffic</li>
            <li>Inter-Cluster heartbeat traffic</li>
          </ul>
        </ul>
      </div>
      <div class='notes'>
        If your cluster utilizes IBM Storwize family products as back-end managed disks (mdisks), this chart may be inaccurate. Due to the way SVC identifies Storwize managed disks, I/O to Storwize family managed disks may be reported as Port to Remote node I/O.  If your cluster uses Storwize family managed disks, Port to Disk charts may be under-reporting throughput, and Port to Remote charts may be over-reporting throughput by an equal amount. Please see the Cluster Replication Throughput chart for a more accurate representation of total replication throughput.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 167</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port to Remote Sent Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p></p>
        This chart shows the throughput of traffic SENT by the SVC or Storwize V7000 port to other nodes in <b>REMOTE</b> clusters.
        <ul>
          <p>This traffic includes:</p>
          <ul class='nested'>
            <li>Global Mirror replication traffic</li>
            <li>Metro Mirror replication traffic</li>
            <li>Inter-Cluster heartbeat traffic</li>
          </ul>
        </ul>
      </div>
      <div class='notes'>
        If your cluster utilizes IBM Storwize family products as back-end managed disks (mdisks), this chart may be inaccurate. Due to the way SVC identifies Storwize managed disks, I/O to Storwize family managed disks may be reported as Port to Remote node I/O.  If your cluster uses Storwize family managed disks, Port to Disk charts may be under-reporting throughput, and Port to Remote charts may be over-reporting throughput by an equal amount. Please see the Cluster Replication Throughput chart for a more accurate representation of total replication throughput.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 168</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MAX CPUs by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the maximum CPU capacity that is available to the group of LPARs in each Shared Processor Pool.
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>Note: <b>Shared Processor Pools</b> can significantly reduce software licensing costs by limiting a GROUP of LPARs using the same software to a Maximum Capacity within a Pool.  The MAX capacity of the shared pool enforces the license cap, eliminating the need to procure a license for all processor cores in the managed system.</p>
        <p><b>Example Scenario</b>: You have an 8-core server with four LPARs, two of which are running ERP software licensed for the 8 cores.  The server is upgraded from 8 cores to 16 cores, but the two ERP LPARs only need 8.</p>
        <p><b>Solution</b>: Create Pool 1 with MAX=8, assign the two ERP LPARs to Pool 1, sharing the 8-core license.  The 2 non-ERP LPARs will default to Pool 0, using all 16-cores.  This saves money by assigning the 8-core ERP license to Pool 1, thus avoiding an increase in ERP licenses when unnecessary.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 169</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total CPU Consumed by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <ul>
          <li><b>Pool 0:</b> This DEFAULT Pool reflects the combined CPU utilization of ALL LPARs using shared pools (0-63).</li>
          <li><b>Pools 1-63:</b> These shared pools are the <b>User Defined</b> pools.  The total CPU utilization of all LPARs in each shared pool is shown for the selected time interval.</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 170</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool - CPU Consumed by LPAR
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This stacked area chart shows the CPU utilization of each LPAR assigned to THIS Shared Pool during the time interval.
        <b>Max CPUs</b> represents the maximum CPUs allowed to be consumed by LPARs assigned to this pool.  This effectively caps a GROUP of LPARs so that they can share their CPUs as opposed to capping each LPAR.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 172</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Computational Memory Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the total of <b>System</b> and <b>Process</b> memory usage by percentage for each HOST in the system.  Filesystem cache is NOT included in this chart.
      </div>
      <div class='definitions'>
        <ul>
          <li><b>System memory</b></li>
          <ul class='secondary-list'>
            <li>Memory that is allocated to the system functions and their operations</li>
          </ul>
          <li><b>Process memory</b></li>
          <ul class='secondary-list'>
            <li>Memory that caches elements other than system functions</li>
            <li>This is typically application functions and associated libraries</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 174</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Internal Disk Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>READ</b> throughput rate from each internal disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 175</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Interal Disk Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>WRITE</b> throughput rate to each internal disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 176</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Internal Disk Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>READ</b> operations issued to each internal disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 177</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Internal Disk Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of <b>WRITE</b> operations issued to each internal disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 178</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Internal Disk Read Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>READ service times</b>, or response time, from each internal disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 179</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Internal Disk Write Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the <b>WRITE service times</b>, or response time, to each internal disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 180</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    SEA Network Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the RECEIVE and SEND network throughput of all the Shared Ethernet Adapters (SEA) interfaces of the VIO server in KB/sec.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 181</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    SEA Network Packet Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the RECEIVE and SEND network packets of all the Shared Ethernet Adapters (SEA) of the VIO server in KB/sec.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 182</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    SEA Network Receive/Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the RECEIVE and SEND network throughput for all Shared Ethernet Adapters (SEA) on the VIO server in KB/s.  This chart can be used to determine which interface has the highest throughput and whether dedicated NICs should be considered.  Link aggregation or upgrading the NICs to a faster interface may also be considered.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 183</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    SEA Network Receive/Send Packets
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the RECEIVE and SEND network packets of all the Shared Ethernet Adapters (SEA) in KB/s.  This chart can be used to determine which interface has the highest throughput and whether dedicated NICs should be considered.  Link aggregation or upgrading the NICs to a faster interface may also be considered.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 184</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host SEA Network Receive + Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the combined network throughput of all the shared ethernet adapters (SEA) in KB/s (received and sent) for all hosts on the server in a "stacked area" view.  These interfaces can be removed from or added to the chart based upon the legend check boxes on the left side of the chart (zoom in).  This frame view can be used to determine which VIO servers have the highest throughput and if additional NICs or re-balancing client LPARs across the SEA adapters should be considered.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 185</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host SEA Network Receive Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual network RECEIVE throughput in KB/s of all the hosts on the server in a "stacked area" view.  This is indicative of the actual data rate transferring through the network in READ operations at the given time period.  This frame view can be used to determine which VIO servers have the highest throughput and if additional NICs or re-balancing client LPARs across the SEA adapters should be considered.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 186</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host SEA Network Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual network SEND throughput in KB/s of all the hosts on the server in a "stacked area" view.  This is indicative of the actual data rate transferring through the network in WRITE operations at the given time period.  This frame view can be used to determine which VIO servers have the highest throughput and if additional NICs or re-balancing client LPARs across the SEA adapters should be considered.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 187</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host SEA Network Packet Receive + Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the combined network packets throughput (received and sent) of all the shared ethernet adapters (SEA) for all hosts on the server in a "stacked area" view.  These interfaces can be removed from or added to the chart based upon the radio buttons at the bottom of the chart (zoom in).  This frame view can be used to determine which VIO servers have the highest throughput and if additional NICs or re-balancing client LPARs across the SEA adapters should be considered.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 188</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host SEA Network Packet Receive Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual network RECEIVE packets in packets/s of all the hosts on the server in a "stacked area" view.  This is indicative of the actual packet rate transferring through the network in READ operations at the given time period.  This frame view can be used to determine which VIO servers have the highest throughput and if additional NICs or re-balancing client LPARs across the SEA adapters should be considered.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 189</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host SEA Network Packet Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the actual network SEND packets in packets/s of all the hosts on the server in a "stacked area" view.  This is indicative of the actual packet rate transferring through the network in WRITE operations at the given time period.  This frame view can be used to determine which VIO servers have the highest throughput and if additional NICs or re-balancing client LPARs across the SEA adapters should be considered.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 196</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Disk Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total number of <b>Host Disk Read Transfers</b> (IO/s) that have occurred on all the hosts on the server in a "stacked area" view.  These values consist of read transfer operations on all adapters.  This server view can be used to determine which hosts have the highest read IO/s rate and if dedicated HBAs or sharing of HBAs between hosts should be considered (VIO/NPIV).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 197</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Disk Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total number of <b>Host Disk Write Transfers</b> (IO/s) that have occurred on all the hosts on the server in a "stacked area" view.  These values consist of write transfer operations on all adapters.  This server view can be used to determine which hosts have the highest write IO/s rate and if dedicated HBAs or sharing of HBAs between hosts should be considered (VIO/NPIV).</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 200</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Real Memory Free
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the amount of FREE memory by all hosts in a "stacked area" view.  Hosts with the most amount of FREE memory can quickly be observed over the specified time range.  This FREE memory is as reported by each operating system.  Some operating systems will use additional memory to cache file(s) data, which is not reported as free memory, but often is "considered" memory which can be reduced or reallocated.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        Benefits and Tips:
        <ul>
          <li>The "Default" stacked area view shows the total amount of FREE memory of all the hosts, to assist in deciding if more memory is required on the server or if memory can be reallocated between hosts.</li>
          <li>Changing "Default" to "Line" shows an Unstacked Line for each Host, to quickly identify the host(s) with the most amount of FREE memory you may choose to reallocate.</li>
          <li>Before deciding  to reallocate or add more for a host or a Server, we recommend viewing this over a time range of 1-3 months or your critical day(s)/time(s).</li>
          <li>The "Host Computational Memory Used" chart should be viewed which shows the amount of Used memory minus cached file data. Hosts with large amounts of cached file data may be additional candidates to reallocate the memory elsewhere.</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 202</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    FC Adapter Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total KB per second (KB/s) from each Fibre Channel (FC) adapter of the host.  You can quickly identify heavily used adapters or if there is an even distribution of throughput across adapters.  By default, a Area  Stacked view is displayed to quickly show the throughput per second for a host.  To verify if there is an even distribution of throughput across adapters, use a Line view to show if individual adapters Lines overlay each other.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <ul>
          <li>If uneven distribution of transfers across adapters</li>
          <ul class='nested'>
            <li>Is SAN Zone definitions correct or changed?</li>
            <li>Check FC ports, cables and GBICs</li>
            <li>Is Load Balancing defined for the devices off these adapters (e.g. disk/tape)?</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 203</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    FC Adapter Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total read KB per second (KB/s) from each Fibre Channel (FC) adapter of the host.  You can quickly identify heavily used adapters or if there is an even distribution of throughput across adapters.  By default, a Area  Stacked view is displayed to quickly show the throughput per second for a host.  To verify if there is an even distribution of throughput across adapters, use a Line view to show if individual adapters Lines overlay each other.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <ul>
          <li>If uneven distribution of transfers across adapters</li>
          <ul class='nested'>
            <li>Is SAN Zone definitions correct or changed?</li>
            <li>Check FC ports, cables and GBICs</li>
            <li>Is Load Balancing defined for the devices off these adapters (e.g. disk/tape)?</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 204</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    FC Adapter Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total write KB per second (KB/s) from each Fibre Channel (FC) adapter of the host.  You can quickly identify heavily used adapters or if there is an even distribution of throughput across adapters.  By default, a Area  Stacked view is displayed to quickly show the throughput per second for a host.  To verify if there is an even distribution of throughput across adapters, use a Line view to show if individual adapters Lines overlay each other.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <ul>
          <li>If uneven distribution of transfers across adapters</li>
          <ul class='nested'>
            <li>Is SAN Zone definitions correct or changed?</li>
            <li>Check FC ports, cables and GBICs</li>
            <li>Is Load Balancing defined for the devices off these adapters (e.g. disk/tape)?</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 205</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    FC Adapter Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total number of transfers per second (IO/s) from/to each Fibre Channel (FC) adapter of the host.  You can quickly identify heavily used adapters or if there is an even distribution of IOs across adapters.  By default, a Area  Stacked view is displayed to quickly show the transfers per second for a host.  To verify if there is an even distribution of transfers across adapters, use a Line view to show if individual adapters Lines overlay each other.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <ul>
          <li>If uneven distribution of transfers across adapters</li>
          <ul class='nested'>
            <li>Is SAN Zone definitions correct or changed?</li>
            <li>Check FC ports, cables and GBICs</li>
            <li>Is Load Balancing defined for the devices off these adapters (e.g. disk/tape)?</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 206</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    FC Adapter Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total number of read transfers per second (IO/s) from each Fibre Channel (FC) adapter of the host.  You can quickly identify heavily used adapters or if there is an even distribution of IOs across adapters.  By default, a Area  Stacked view is displayed to quickly show the transfers per second for a host.  To verify if there is an even distribution of transfers across adapters, use a Line view to show if individual adapters Lines overlay each other.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <ul>
          <li>If uneven distribution of transfers across adapters</li>
          <ul class='nested'>
            <li>Is SAN Zone definitions correct or changed?</li>
            <li>Check FC ports, cables and GBICs</li>
            <li>Is Load Balancing defined for the devices off these adapters (e.g. disk/tape)?</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 207</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    FC Adapter Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total number of write transfers per second (IO/s) to each Fibre Channel (FC) adapter of the host.  You can quickly identify heavily used adapters or if there is an even distribution of IOs across adapters.  By default, a Area  Stacked view is displayed to quickly show the transfers per second for a host.  To verify if there is an even distribution of transfers across adapters, use a Line view to show if individual adapters Lines overlay each other.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <ul>
          <li>If uneven distribution of transfers across adapters</li>
          <ul class='nested'>
            <li>Is SAN Zone definitions correct or changed?</li>
            <li>Check FC ports, cables and GBICs</li>
            <li>Is Load Balancing defined for the devices off these adapters (e.g. disk/tape)?</li>
          </ul>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 210</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for the entire storage subsystem. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 211</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from the entire storage subsystem. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 212</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average size of the transfers in KB per second for the entire storage subsystem. You can quickly identify large vs. small transfer sizes. Large transfer sizes often indicate sequential processing workloads while small transfer sizes often indicate random transactional workloads. This is a non-stacked line view, which quickly allows the large size transfers to stand above the small size transfers.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 213</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Transfer Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read and write activities for the entire storage unit. This will allow you to identify times when the storage unit is intensively reading vs. writing.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 214</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Cache Hit Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads that are fulfilled by data from cache rather than requiring an actual read from a disk drive for the entire storage unit. In newer versions of controller firmware, you will also see percentages for write cache hits and SSD read cache hits.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 215</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Controller Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for the selected controllers. By default, a stacked area view is displayed to quickly illustrate the total throughput for both storage controllers. This chart will allow you visualize the workload per controller and determine any imbalance of processing.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 216</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Controller Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of combined read and write transfers per second (IOs) for the selected controllers. By default, a stacked area view is displayed to quickly illustrate the total transfers for both storage controllers. This chart will allow you visualize the workload per controller and determine any imbalance of processing.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 217</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Controller Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) for the selected controllers. By default, a stacked area view is displayed to quickly illustrate the total number read transfers per second for both storage controllers. This chart will allow you visualize the workload per controller and determine any imbalance of processing.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 218</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Controller Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) for the selected controllers. By default, a stacked area view is displayed to quickly illustrate the total number of  write transfers per second for both storage controllers. This chart will allow you visualize the workload per controller and determine any imbalance of processing.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 219</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Controller Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average size of the transfers in KB per second for the selected controllers. You can quickly identify large vs. small transfer sizes. Large transfer sizes often indicate sequential processing workloads while small transfer sizes often indicate random transactional workloads. This is a non-stacked line view, which quickly allows the large size transfers to stand above the small size transfers.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 220</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Controller Transfer Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read and write transfers for the selected controllers. By default, a non-stacked line chart is displayed.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 221</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Controller Cache Hit Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads that are fulfilled by data from cache rather than requiring an actual read from a disk drive for the selected controllers. In newer versions of controller firmware, you will also see percentages for write cache hits and SSD read cache hits.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 222</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Array/Disk Pool Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for all selected arrays and disk pools. By default, a "stacked area" view is displayed to quickly illustrate the total throughput for all selected arrays and disk pools. This chart will allow you visualize the workload per array or disk pool and easily identify any "hot" arrays or disk pools.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 223</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Array/Disk Pool Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of combined read and write transfers per second (IOs) for all selected arrays and disk pools. By default, a stacked area view is displayed to quickly illustrate the total transfers for all selected arrays and disk pools. This chart will allow you visualize the workload per array or disk pool and easily identify any "hot" arrays or disk pools.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 224</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Array/Disk Pool Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) for the selected arrays and disk pools. By default, a stacked area view is displayed to quickly illustrate the total number of read transfers per second for all selected arrays and disk pools. This chart will allow you visualize the workload per array or disk pool and easily identify any read intensive arrays or disk pools.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 225</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Array/Disk Pool Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) for the selected arrays and disk pools. By default, a stacked area view is displayed to quickly illustrate the total number of write transfers per second for all selected arrays and disk pools. This chart will allow you visualize the workload per array or disk pool and easily identify any write intensive arrays or disk pools.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 226</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Array/Disk Pool Transfer Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read and write transfers for the selected arrays and disk pools. By default, a non-stacked line chart is displayed.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 227</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Array/Disk Pool Read Transfer Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read transfers for the selected arrays and disk pools. By default, a non-stacked line chart is displayed.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 228</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Array/Disk Pool Write Transfer Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of write transfers for the selected arrays and disk pools. By default, a non-stacked line chart is displayed.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 229</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for the selected LUNs. By default, a "stacked area" view is displayed to quickly illustrate the total sum of throughput for the selected LUNs. This chart will allow you visualize the workload per LUN and easily identify any "hot" LUNs.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 230</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of combined read and write transfers per second (IOs) for all selected LUNs. By default, a stacked area view is displayed to quickly illustrate the total transfers for all selected LUNs. This chart will allow you visualize the workload per LUN and easily identify any "hot" LUNs.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 231</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) for the selected LUNs. By default, a "stacked area" view is displayed to quickly illustrate the read transfers per second for all LUNs. This chart will allow you visualize the workload per array and easily identify any read intensive LUNs.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 232</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) for the selected LUNs. By default, a "stacked area" view is displayed to quickly illustrate the write transfers per second for all LUNs. This chart will allow you visualize the workload per array and easily identify any write intensive LUNs.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 233</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average size of the transfers in KB per second for the selected LUNs. You can quickly identify large vs. small transfer sizes. Large transfer sizes often indicate sequential processing workloads while small transfer sizes often indicate random transactional workloads. This is a non-stacked line view, which quickly allows the large size transfers to stand above the small size transfers.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 234</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Transfer Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read and write transfers for the selected LUNs. By default, a non-stacked line chart is displayed.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 235</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Read Transfer Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read transfers for the selected LUNs. By default, a non-stacked line chart is displayed.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 236</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Write Transfer Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of write transfers for the selected LUNs. By default, a non-stacked line chart is displayed.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 237</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Cache Hit Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads that are fulfilled by data from cache rather than requiring an actual read from a disk drive for the selected LUNs.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 238</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Read Cache Hit Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads that are fulfilled by data from cache rather than requiring an actual read from a disk drive for the selected LUNs.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 239</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Write Cache Hit Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of writes that are fulfilled by cache rather than requiring writing directly to disk for the selected LUNs.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 240</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN SSD Read Cache Hit Percentages
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads that are fulfilled by data from cache rather than requiring an actual read from a SSD for the selected LUNs.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 241</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Read Cache Hits Percentage (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of time host-initiated reads are serviced by the SVC or Storwize V7000 cache, rather than reading from back-end disks. This chart shows the average read cache hit percentage for all virtual disks or volumes in the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 242</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Queue Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average read and write queue times for all managed disks on the cluster. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 243</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Read Cache Hits Percentage (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of time host-initiated reads are serviced by the SVC or Storwize V7000 cache, rather than reading from back-end disks. This chart shows the average read cache hit percentage per I/O group.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 244</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Read Queue Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average read queue times for all managed disks on the cluster, at an I/O group level. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 245</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Queue Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average write queue times for all managed disks on the cluster, at an I/O group level. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 246</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Read Transfer Sizes (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the transfer size of READ operations issued to the virtual disks or volumes in this managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 247</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Write Transfer Sizes (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the transfer size of WRITE operations issued to the virtual disks or volumes in this managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 248</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Read Queue Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the read queue times for the managed disks in this managed disk group or storage pool. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 249</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Write Queue Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the write queue times for the managed disks in this managed disk group or storage pool. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 250</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Backend Read Transfer Sizes (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the transfer size of READ operations issued to the managed disks in this managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 251</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    MDG/Pool Backend Write Transfer Sizes (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the transfer size of WRITE operations issued to the managed disks in this managed disk group or storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 252</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Read Queue Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the read queue times for each managed disk. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 253</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Write Queue Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the write queue times for each managed disk. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 254</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Read Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the transfer size of READ operations issued to each managed disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 255</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Write Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the transfer size of WRITE operations issued to each managed disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 256</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Queue Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average read queue times for all managed disks on the cluster, at a node level. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 257</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Queue Times (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the average write queue times for all managed disks on the cluster, at a node level. Queue times indicate how long an I/O transaction is held in the SVC or Storwize V7000 queue before it can be sent to the back-end storage array. High queue times indicate the back-end storage may be overloaded and not able to keep up with the workload being driven to it.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 258</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Cache Hits Percentage (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of time host-initiated reads are serviced by the SVC or Storwize V7000 cache, rather than reading from back-end disks. This chart shows the average read cache hit percentage per node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 259</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node CPU Percent Compression
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        When real-time compression is in use, this chart shows the percentage of time the SVC or Storwize V7000's CPUs are busy performing compression-related work. Note that this is a percentage of the CPU cores dedicated to compression duties, and can therefore range from 0% to 100% independent of Node CPU Percent Busy, which is displayed in a separate chart.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 260</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Read Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the transfer size of READ operations issued to each virtual disk or volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 261</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Write Transfer Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the transfer size of WRITE operations issued to each virtual disk or volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 262</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume/Vdisk Read Cache Hits Percentage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of time host-initiated reads are serviced by the SVC or Storwize V7000 cache, rather than reading from back-end disks. This chart shows the cache hit percentage per volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 263</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Virtual Memory Allocation
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This is the total <b>Virtual Memory / Paging Space Allocation</b> of all the active hosts on the server in a "stacked area" view.  It is important to note that this particular chart does not illustrate the amount of virtual memory / paging space utilized by each host in terms of actual usage, but rather the amount of virtual memory / paging space ALLOCATED to each host.  The chart "Host Virtual Memory Utilization" is a better indication of each host's virtual memory / paging space usage.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 264</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Virtual Memory Utilization
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the utilization of virtual memory / paging space for all hosts on the server in a "non-stacked line" view. Each line represents the percent of that host's page space utilization relative to 100%. If a host shows a gradual increase towards 100%, this might be indicative of a memory related issue. A host ideally should be using very little of its virtual memory / paging space so read the notes below if more than 5-10% of page space is being used.</p>
        <p>For this chart to represent the entire SERVER, you must have the Galileo agent installed and fully operational on ALL LPARs.</p>
      </div>
      <div class='notes'>
        <p>Notes:</p>
        If the Paging Space becomes fully used, the OS will not allow new processes to be started and will begin to terminate existing processes in an attempt to survive.  A gradual increase of Paging Space usage over time should be investigated immediately to avoid a system outage.
        <ul>
          <li>Things to Check:</li>
          <ul>
            <li>If the Scan to Free Ratio is greater than 4 on average, then memory is very active (over 75% utilized), which could be a sign of needing more memory, memory is over committed or tuning is required.</li>
            <li>"System Paging" chart for thrashing</li>
            <li>"Real Memory" and "Memory Use" charts for the past month to see if memory allocations were reduced</li>
            <li>DB memory buffers may have been increased or additional database instances were started</li>
            <li>JAVA HEAP/memory was increased in applications</li>
            <li>New applications were added using more memory</li>
            <li>Memory leaks, often with new applications or JAVA applications</li>
            <li>"Large Page Support" was activated and over allocated</li>
          </ul>
          <br>
            <li>If Huge/Large Page Memory is allocated during the selected time range, and a high Scan/Free Ratio is occurring, please refer to the "Huge/Large Page Memory" charts and their Help Panels to identify if free Large Page memory exists, which can be unallocated and made available for general use.</li>
          </br>
        </ul>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 270</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for the entire storage subsystem. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 271</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from the entire storage subsystem. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 272</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to the subsystem. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 273</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Transfers by Cache Hits (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads and writes that are fulfilled by data from cache rather than requiring an actual read from a disk drive or a direct write to a disk drive for the entire storage unit.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 274</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Throughput by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for the entire storage subsystem. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 275</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Transfers by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from the entire storage subsystem. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk transfers for the entire storage unit.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 276</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to the subsystem. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 277</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Throughput by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read and write throughput for the entire storage unit. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 278</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Transfers by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read and write transfers for the entire storage unit. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 279</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Read Throughput (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This charts shows the percentages of read throughput for the entire storage unit. The data in the chart is broken down by the type of IO, highlighting the size of the operation.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Small transfer sizes are <= 8 KB</li>
<li>Medium transfer sizes are > 8 KB and <= 64 KB</li>
<li>Large transfer sizes are > 64 KB and <= 512 KB</li>
<li>Very large transfer sizes are > 512 KB</li>
</ul>
<h1>Chart - 280</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Write Throughput (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This charts shows the percentages of write throughput for the entire storage unit. The data in the chart is broken down by the type of IO, highlighting the size of the operation.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Small transfer sizes are <= 8 KB</li>
<li>Medium transfer sizes are > 8 KB and <= 64 KB</li>
<li>Large transfer sizes are > 64 KB and <= 512 KB</li>
<li>Very large transfer sizes are > 512 KB</li>
</ul>
<h1>Chart - 281</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Read Transfers (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This charts shows the percentages of read transfers for the entire storage unit. The data in the chart is broken down by the type of IO, highlighting the size of the operation.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Small transfer sizes are <= 8 KB</li>
<li>Medium transfer sizes are > 8 KB and <= 64 KB</li>
<li>Large transfer sizes are > 64 KB and <= 512 KB</li>
<li>Very large transfer sizes are > 512 KB</li>
</ul>
<h1>Chart - 282</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Write Transfers (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This charts shows the percentages of write transfers for the entire storage unit. The data in the chart is broken down by the type of IO, highlighting the size of the operation.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Small transfer sizes are <= 8 KB</li>
<li>Medium transfer sizes are > 8 KB and <= 64 KB</li>
<li>Large transfer sizes are > 64 KB and <= 512 KB</li>
<li>Very large transfer sizes are > 512 KB</li>
</ul>
<h1>Chart - 283</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Read Transfers Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads from the subsystem. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk as well as the size of the operation. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<table>
<tr>
<td>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
</td>
<td>
<ul>
<li>Small transfer sizes are <= 8 KB</li>
<li>Medium transfer sizes are > 8 KB and <= 64 KB</li>
<li>Large transfer sizes are > 64 KB and <= 512 KB</li>
<li>Very large transfer sizes are > 512 KB</li>
</ul>
</td>
</tr>
</table>
<h1>Chart - 284</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Subsystem Write Transfers Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for writes to the subsystem. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk as well as the size of the operation. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<table>
<tr>
<td>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
</td>
<td>
<ul>
<li>Small transfer sizes are <= 8 KB</li>
<li>Medium transfer sizes are > 8 KB and <= 64 KB</li>
<li>Large transfer sizes are > 64 KB and <= 512 KB</li>
<li>Very large transfer sizes are > 512 KB</li>
</ul>
</td>
</tr>
</table>
<h1>Chart - 285</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for each module. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit by module.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 286</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from each module. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit by module.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 287</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to each module. Service times indicate how quickly each module is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 288</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Transfers by Cache Hits (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads and writes that are fulfilled by data from cache rather than requiring an actual read from a disk drive or a direct write to a disk drive for each module.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 289</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Throughput by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for each module. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit by module.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 290</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Transfers by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from each module. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit by module.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 291</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to each module. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. Service times indicate how quickly each module is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 292</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Throughput by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read and write throughput for each module. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 293</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Module Transfers by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read and write transfers for each module. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 294</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for each pool. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 295</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of read data in KB per second for each pool. By default, a stacked area view is displayed to quickly illustrate the total sum of disk read throughput for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 296</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of write data in KB per second for each pool. By default, a stacked area view is displayed to quickly illustrate the total sum of disk write throughput for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 297</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from each pool. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 298</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) from each pool. By default, a stacked area view is displayed to quickly illustrate the total read transfers per second for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 299</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) from each pool. By default, a stacked area view is displayed to quickly illustrate the total write transfers per second for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 300</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Average Service Times (Read/Write)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to each pool. Service times indicate how quickly each pool is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 301</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Average Read Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads from each pool. Service times indicate how quickly each pool is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 302</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Average Write Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for writes to each pool. Service times indicate how quickly each pool is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 303</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Read Throughput by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of read data in KB per second for each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk read throughput for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 304</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Write Throughput by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of write data in KB per second for each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk write throughput for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 305</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Read Transfers by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) from each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total write transfers per second for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 306</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Write Transfers by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) from each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total read transfers per second for the entire storage unit by pool.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 307</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Read Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads from each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. Service times indicate how quickly each pool is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 308</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Write Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for writes to each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. Service times indicate how quickly each pool is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 309</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Read Transfers by Cache Hits (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads that are fulfilled by data from cache rather than requiring an actual read from a disk drive for each pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 310</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Write Transfers by Cache Hits (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of writes that are fulfilled by data from cache rather than requiring a direct write to a disk drive for each pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 311</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Read Throughput by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read throughput for each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 312</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Write Throughput by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of write throughput for each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 313</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Read Transfers by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read transfers for each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 314</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pool Write Transfers by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of write transfers for the each pool. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 315</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for each volume. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 316</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of read data in KB per second for each volume. By default, a stacked area view is displayed to quickly illustrate the total sum of disk read throughput for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 317</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of write data in KB per second for each volume. By default, a stacked area view is displayed to quickly illustrate the total sum of disk write throughput for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 318</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from each volume. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 319</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) from each volume. By default, a stacked area view is displayed to quickly illustrate the total read transfers per second for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 320</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) from each volume. By default, a stacked area view is displayed to quickly illustrate the total write transfers per second for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 321</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Average Service Times (Read/Write)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to each volume. Service times indicate how quickly each volume is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 322</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Average Read Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads from each volume. Service times indicate how quickly each volume is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 323</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Average Write Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for writes to each volume. Service times indicate how quickly each volume is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 324</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Throughput by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of read data in KB per second for each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk read throughput for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 325</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Throughput by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of write data in KB per second for each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk write throughput for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 326</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Transfers by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) from each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total write transfers per second for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 327</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Transfers by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) from each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total read transfers per second for the entire storage unit by volume.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 328</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads from each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. Service times indicate how quickly each volume is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 329</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for writes to each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. Service times indicate how quickly each volume is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 330</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Transfers by Cache Hits (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads that are fulfilled by data from cache rather than requiring an actual read from a disk drive for each volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 331</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Transfers by Cache Hits (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of writes that are fulfilled by data from cache rather than requiring a direct write to a disk drive for each volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 332</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Throughput by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read throughput for each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 333</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Throughput by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of write throughput for each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 334</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Transfers by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read transfers for each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 335</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Transfers by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of write transfers for the each volume. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 336</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for each host. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 337</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of read data in KB per second for each host. By default, a stacked area view is displayed to quickly illustrate the total sum of disk read throughput for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 338</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of write data in KB per second for each host. By default, a stacked area view is displayed to quickly illustrate the total sum of disk write throughput for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 339</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from each host. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 340</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) from each host. By default, a stacked area view is displayed to quickly illustrate the total read transfers per second for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 341</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) from each host. By default, a stacked area view is displayed to quickly illustrate the total write transfers per second for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 342</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Average Service Times (Read/Write)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to each host. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 343</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Average Read Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads from each host. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 344</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Average Write Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for writes to each host. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 345</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Read Throughput by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of read data in KB per second for each host The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk read throughput for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 346</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Write Throughput by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of write data in KB per second for each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total sum of disk write throughput for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 347</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Read Transfers by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read transfers per second (IOs) from each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total write transfers per second for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 348</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Write Transfers by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of write transfers per second (IOs) from each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. By default, a stacked area view is displayed to quickly illustrate the total read transfers per second for the entire storage unit by host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 349</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Read Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads from each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 350</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Write Service Times by Cache Hits/Misses
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for writes to each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 351</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Read Transfers by Cache Hits (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of reads that are fulfilled by data from cache rather than requiring an actual read from a disk drive for each host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 352</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Write Transfers by Cache Hits (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of writes that are fulfilled by data from cache rather than requiring a direct write to a disk drive for each host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 353</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Read Throughput by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read throughput for each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 354</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Write Throughput by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of write throughput for each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 355</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Read Transfers by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of read transfers for each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 356</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Write Transfers by Cache Hits/Misses (%)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentages of write transfers for the each host. The data in the chart is broken down by the type of IO, highlighting operations to cache (including SDD) versus operations direct to spinning disk.
      </div>
    </div>
  </div>
</div>
<ul>
<li>Read Memory Hit (RMH)</li>
<li>Read SSD Hit (RSH)</li>
<li>Read Miss (RM)</li>
<li>Write Hit (WH)</li>
<li>Write Miss (WM)</li>
</ul>
<h1>Chart - 357</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for each FC port. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit by FC port.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 358</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from each FC port. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit by FC port.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 359</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to each port. Service times indicate how quickly each port is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 360</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Port Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of combined read and write data in KB per second for each host port. By default, a stacked area view is displayed to quickly illustrate the total sum of disk throughput for the entire storage unit by host port.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 361</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Port Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of read and write transfers per second (IOs) from each host port. By default, a stacked area view is displayed to quickly illustrate the total transfers per second for the entire storage unit by host port.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 362</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Port Service Times
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the service times, or response times, for reads and writes from/to each host port. Service times indicate how quickly the storage unit is responding to requests from a host.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 363</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Filesystem Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the total size of each mounted filesystem in MB.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 364</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Filesystem Usage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the used capacity of each mounted filesystem in MB.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 365</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Filesystem Percent Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the used capacity of each mounted filesystem as a percentage.  In the default (line) view, this allows you to quickly determine if any filesystems are running out of space from a percentage perspective.  However, since this is presented as a percentage, you should also refer to the 'Host Filesystem Free' chart to determine if the amount of free space is truly of concern.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 366</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Filesystem Free
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the free capacity of each mounted filesystem in MB.</p>
      </div>
      <div class='definitions'></div>
    </div>
  </div>
</div>
<h1>Chart - 367</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Filesystem Inode Usage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the number of inodes used for each mounted filesystem.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>In some cases, you may be unable to add new files to a filesystem even though it appears as though you have free space (MB).  This could be because all inodes on the given filesystem are used, which is most likely to happen on a filesystem with a very large number of (typically small) files.  The total number of inodes available to a filesystem is sometimes a static value, which means that the only way to increase it is to actually destroy and recreate a new filesystem.  However, this value can sometimes be dynamically increased as needed.  Whether or not this is a static or dynamic value is a function of the specific type of filesystem in use.  As such, refer to filesystem type documentation to determine if you can dynmically increase inodes.</p>
        <p>You can also refer to the 'Host Filesystem Inode Percent Used' chart to determine if any particular filesystem is approaching the inode limit.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 368</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Filesystem Inode Percent Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>This chart shows the percentage of inodes used for each mounted filesystem.</p>
      </div>
      <div class='definitions'></div>
      <div class='notes'>
        <p>In some cases, you may be unable to add new files to a filesystem even though it appears as though you have free space (MB).  This could be because all inodes on the given filesystem are used, which is most likely to happen on a filesystem with a very large number of (typically small) files.  The total number of inodes available to a filesystem is sometimes a static value, which means that the only way to increase it is to actually destroy and recreate a new filesystem.  However, this value can sometimes be dynamically increased as needed.  Whether or not this is a static or dynamic value is a function of the specific type of filesystem in use.  As such, refer to filesystem type documentation to determine if you can dynmically increase inodes.</p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 370</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows average read and write througput across the cluster for all filesystems on all the nodes of the GPFS cluster. This graph is the indication of total Disk I/O per second across the cluster.The values shown are in KB/Sec.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 371</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Clients Network Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the average Network Throughput: Data SENT and RECEIVED in KB/sec. The SENT and RECEIVED values shown are across all interfaces on all nodes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 372</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Read/Write Latency
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows average time taken in ms ( latency ) for file READ and WRITE operations across all the filesystems on all the nodes of the GPFS cluster. This graph also shows how quickly the Metadata is being updated.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 373</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Open/Close Latency
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows average time taken in ms ( latency ) for file OEPN and CLOSE operations across all the filesystems on all the nodes of the GPFS cluster. This graph also shows how quickly the Metadata is being updated.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 374</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Create/Delete Latency
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows average time taken in ms ( latency ) for file CREATE and DELETE operations across all the filesystems on all the nodes of the GPFS cluster. This graph also shows how quickly the Metadata is being updated.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 375</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Read/Write Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the average number of File READ and File WRITE operations per seconds across all file systems in the cluster. This graph also indicates GPFS metadata activity.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 376</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Open/Close Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the average number of File OPEN and File CLOSE operations per seconds across all file systems in the cluster . This graph also indicates GPFS metadata activity.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 377</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Create/Delete Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the average number of File CREATE and File DELETE operations per seconds across all file systems in the cluster . This graph also indicates GPFS metadata activity.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 378</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Throughput by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the READ+WRITE Throughput of each Filesystem in KB/sec . The READ and WRITE values shown are across all nodes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 379</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Read Throughput by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the READ Throughput of each Filesystem in KB/sec . The values shown are across all nodes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 380</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Write Throughput by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the WRITE Throughput of each Filesystem in KB/sec . The values shown are across all nodes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 381</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total/Used by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total and Used sizes in GB of each filesystem in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 382</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Size by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total size in GB of each filesystem in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 383</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Used Size by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Used size in GB of each filesystem in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 384</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Free Size by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Free (available) size in GB of each filesystem in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 385</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Used by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % Used ( Used Size / Total Size x 100 ) of each filesystem in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 386</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Free by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % Free ( Used Size / Total Size x 100 ) of each filesystem in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 387</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total/Used Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total Soft Quota Limit and Used Quota in GB of each fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 388</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Soft Quota Limit by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total Soft Quota Limit in GB of each fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 389</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Used Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Used Quota in GB of each fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 390</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Free Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Availbae Quota in GB of each fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 391</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Used Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % of Used Quota in GB of each fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 392</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Free Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % of Free Quota in GB of each fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 393</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total/Used Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total and Used sizes in GB of each Fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 394</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Soft Quota Limit by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total size in GB of each Fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 395</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Used Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Used size in GB of each Fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 396</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Free Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Free size in GB of each Fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 397</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Used Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % Used size of each Fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 398</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Free Soft Quota by Fileset
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % Free size of each Fileset in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 399</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Throughput by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the number of KB READ and WRITTEN on each of the pools for each filesystem within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 400</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Read Throughput by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the number of KB READ on each of the pools for each filesystem within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 401</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Write Throughput by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the number of KB WRITTEN on each of the pools for each filesystem within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 402</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total/Used Size by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total and Used sizes in GB of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 403</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total size in GB of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 404</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Used Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Used size in GB of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 405</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Free Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Free size in GB of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 406</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Used Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % Used size of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 407</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Free Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % Free size of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 408</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Throughput by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the number of KB READ and WRITTEN on each of the pools for each filesystem within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 409</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Read Throughput by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the number of KB READ on each of the pools for each filesystem within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 410</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Write Throughput by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the number of KB WRITTEN on each of the pools for each filesystem within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 411</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total/Used Size by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total and Used sizes in GB of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 412</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Total size in GB of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 413</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Used Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Used size in GB of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 414</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Free Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Free size in GB of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 415</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Used Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % Used size of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 416</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    % Free Size by Pool
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the % Free size of each Pool in 30 min intervals.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 417</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pre-Migrated Size by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the size of Pre-Migrated files by filesystem. Pre-Migrated files are the files
        that have been recalled from the HSM tapes but not yet modified. The list of these files can be
        obtained by running the 'dsmls' command in a specific directory. The 'File State' of these files
        will be shown as 'p'.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 418</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Migrated Size by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the size of Migrated files by filesystem. Migrated files are the files
        that have been miigrated to the HSM tapes and have a stub file locally on the disk. The
        list of these files can be obtained by running the 'dsmls' command in a specific directory.
        The 'File State' of these files will be shown as 'm'. These files will not occupy any space
        on the disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 419</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Pre-Migrated Files by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the total number of Pre-Migrated files by filesystem. Pre-Migrated files are the files
        that have been recalled from the HSM tapes but not yet modified. The list of these files can be
        obtained by running the 'dsmls' command in a specific directory. The 'File State' of these files
        will be shown as 'p'.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 420</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Migrated Files by Filesystem
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the total number of Migrated files by filesystem. Migrated files are the files
        that have been recalled from the HSM tapes but not yet modified. The list of these files can be
        obtained by running the 'dsmls' command in a specific directory. The 'File State' of these files
        will be shown as 'm'.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 421</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    SONASInterfaceNodesCPUBusy
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        "This Graph shows the sum of Percentage of CPU time spent in System
      </div>
    </div>
  </div>
</div>
<h1>Chart - 422</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % User
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent in User mode for each interface node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 423</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % System
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent in System mode for each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 424</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % IO Wait
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent I/O mode for each node. This graph also indicates latecny of disk I/O of each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 425</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % Idle
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent in Idle mode for each node. This graph also indicates processing load for each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 426</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU Context Switches
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Most commonly, within some scheduling scheme, one process needs to be switched out of the CPU so another process can run. This context switch can be triggered by the process making itself unrunnable, such as by waiting for an I/O or synchronization operation to complete.This Graph shows the number  of CPU Context Switches per second.Context switches are usually computationally intensive, and much of the design of operating systems is to optimize the use of context switches. Switching from one process to another requires a certain amount of time for doing the administration - saving and loading registers and memory maps, updating various tables and lists etc.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 427</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU Interrupts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        In systems programming, an interrupt is a signal to the processor emitted by hardware or software indicating an event that needs immediate attention. An interrupt alerts the processor to a high-priority condition requiring the interruption of the current code the processor is executing, the current thread. The processor responds by suspending its current activities, saving its state, and executing a small program called an interrupt handler (or interrupt service routine, ISR) to deal with the event. This interruption is temporary, and after the interrupt handler finishes, the processor resumes execution of the previous thread. This Graph shows the sum  of CPU Hardware and Software Interrupts per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 428</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % Hardware Interrupts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of of CPU Hardware Interrupts per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 429</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % Software Interrupts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of of CPU Software Interrupts per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 430</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total memory installed on the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 431</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Buffer Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total memory used in GB by File Buffers.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 432</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cached Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total memory used in GB as Cache.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 433</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Free Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Free memory ( Memory Installed - Memory Used by Processes) on the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 434</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Swap Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total swap memory (Paging Space) that is created on the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 435</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Swap Free Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Used swap memory (Paging Space) that is created on the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 436</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Throughput by Node and by Interface
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows sum of network data SENT and RECEIVED in KB/Sec by all Public Network Interfaces for each node. This graph indicates the Public (Clients) network load on each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 437</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Received Throughput by Node and by Interface
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows sum of network data RECEIVED in KB/Sec by all Public Network Interfaces for each node. This graph indicates the Public (Clients) network load on each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 438</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Transmitted Throughput by Node and by Interface
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows sum of network data SENT in KB/Sec by all Public Network Interfaces for each node. This graph indicates the Public (Clients) network load on each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 439</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Packets by Node and by Interface
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows sum of network packets SENT and RECEIVED by all Public Network Interfaces for each node. This graph indicates the Public (Clients) network load on each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 440</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Received Packets by Node and by Interface
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows sum of network packets RECEIVED by all Public Network Interfaces for each node. This graph indicates the Public (Clients) network load on each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 441</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Transmitted Packets by Node and by Interface
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows sum of network packets SENT by all Public Network Interfaces for each node. This graph indicates the Public (Clients) network load on each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 442</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Network Errors by Node and by Interface
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows sum of network errors on each Public (Clients) Network Interface for each node. The Network Errors shown are a) sum of network drops sent and received b) sum of network errors sent and received and c) Network Collisions.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 443</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % Busy
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent in System, User for each interface node. This Graph indicates how busy the system is.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 444</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % User
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent in User mode for each interface node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 445</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % System
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent in System mode for each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 446</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % IO Wait
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent I/O mode for each node. This graph also indicates latecny of disk I/O of each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 447</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % Idle
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the sum of Percentage of CPU time spent in Idle mode for each node. This graph also indicates processing load for each node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 448</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU Context Switches
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Most commonly, within some scheduling scheme, one process needs to be switched out of the CPU so another process can run. This context switch can be triggered by the process making itself unrunnable, such as by waiting for an I/O or synchronization operation to complete.This Graph shows the number  of CPU Context Switches per second.Context switches are usually computationally intensive, and much of the design of operating systems is to optimize the use of context switches. Switching from one process to another requires a certain amount of time for doing the administration - saving and loading registers and memory maps, updating various tables and lists etc.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 449</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU Interrupts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        In systems programming, an interrupt is a signal to the processor emitted by hardware or software indicating an event that needs immediate attention. An interrupt alerts the processor to a high-priority condition requiring the interruption of the current code the processor is executing, the current thread. The processor responds by suspending its current activities, saving its state, and executing a small program called an interrupt handler (or interrupt service routine, ISR) to deal with the event. This interruption is temporary, and after the interrupt handler finishes, the processor resumes execution of the previous thread. This Graph shows the sum  of CPU Hardware and Software Interrupts per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 450</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % Hardware Interrupts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of of CPU Hardware Interrupts per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 451</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    CPU % Software Interrupts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of of CPU Software Interrupts per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 452</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total memory installed on the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 453</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Buffer Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total memory used in GB by File Buffers.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 454</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cached Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total memory used in GB as Cache.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 455</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Free Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Free memory ( Memory Installed - Memory Used by Processes) on the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 456</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Swap Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total swap memory (Paging Space) that is created on the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 457</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Swap Free Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the Used swap memory (Paging Space) that is created on the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 458</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Transfers by Node and Disk
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of disk transfers ( READ + WRITE ) per second for all 'DM-#' disks for each node. This graph indicates number of IOPS (I/O Operations) per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 459</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Read Transfers by Node and Disk
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of disk READ transfers per second for all 'DM-#' disks for each node. This graph indicates number of IOPS (I/O Operations) per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 460</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Write Transfers by Node and Disk
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of disk WRITE transfers per second for all 'DM-#' disks for each node. This graph indicates number of IOPS (I/O Operations) per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 461</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Total Transfers by Node
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of disk transfers ( READ + WRITE ) per second for each 'DM-#' disks on all nodes. This graph indicates number of IOPS (I/O Operations) per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 462</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Read Transfers by Node
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of disk READ transfers per second for each 'DM-#' disks on all nodes. This graph indicates number of IOPS (I/O Operations) per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 463</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Write Transfers by Node
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This Graph shows the total number of disk WRITE transfers per second for each 'DM-#' disks on all nodes. This graph indicates number of IOPS (I/O Operations) per second.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 464</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    LUN Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the LUN service times, or response times, in milliseconds for read and write operations for the selected LUNs. This chart will allow you to quickly determine which LUNs have poor service times.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 465</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Drive Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the drive service times, or response times, in milliseconds for read and write operations for the selected drives. This chart will allow you to quickly determine which drives have poor service times.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 500</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS READ and WRITE throughput in KB/Sec of a node. The values are collected using GPFS 'mmpmon' command with 'io_s' option. This chart is the indication of the GPFS I/O service-rate of a node, from the application point of view at the GPFS filesystem layer.  Values are displayed for only those nodes that have Galileo GPFS Agent Installed. The throughout values are the sum of throughputs of the GPFS file systems that are mounted on the node. If no  GPFS file systems are mounted on a node, then the throughput of that node is null.  The 'mmpmon' values are collected and aggregated based on the time period chosen as selected in Galileo Agent GUI.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results and there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect these results and there can be many reasons why adjacent values differ. This must be taken into account when  interpreting results. The occasional zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period ( the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.  This chart can be used to determine: GPFS data usage patterns at a particular time of the day, if a node is serving significantly more I/O than other nodes in the cluster and the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 501</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays GPFS READ throughput in KB/Sec of a node using the 'mmpmon'  command with 'io_s' option. This chart indicates the overall GPFS I/O READ rate of a node, from the application point of view at the GPFS filesystem layer.  Values are displayed for only those nodes that have Galileo Agent Installed. The throughout values are the sum of GPFS READs of all the GPFS filesystems that are mounted on the node. If no  GPFS fileystems are mounted on a node, then the READ throughput of that node is  null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen in the Galileo Agent GUI. Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results. The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 502</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays GPFS WRITE throughput in KB/Sec of a node using the 'mmpmon' command with 'io_s' option. This chart indicates the I/O WRITE rate of a node, from the application point of view at the GPFS filesystem layer. The io_s request presents this as a sum of the GPFS WRITES for the entire node. Values are displayed for only those nodes that have Galileo Agent Installed. The throughput values are the sum of WRITES throughputs of the GPFS filesystems that are mounted on the node. If no  GPFS fileystems are mounted on a node, then the throughput of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 503</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Total Read and Write Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS READ and WRITE Operations per second of each node  using the 'mmpmon' io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a node, from the application point of view at the GPFS filesystem layer. The io_s request presents this as a sum for the entire node. Values are displayed for only those nodes that have Galileo Agent Installed. The throughput values are the sum of throughputs of the GPFS filesystems that have been mounted. If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 504</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays  GPFS READ  Operations of each node  using the 'mmpmon' io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a node, from the application point of view at the GPFS filesystem layer. The io_s request presents this as a sum for the entire node. Values are displayed for only those nodes that have Galileo Agent Installed. The throughput values are the sum of throughputs of the GPFS filesystems that have been mounted. If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 505</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays  GPFS Write Operations of each node  using the 'mmpmon' io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a node, from the application point of view at the GPFS filesystem layer. The io_s request presents this as a sum for the entire node. Values are displayed for only those nodes that have Galileo Agent Installed. The throughput values are the sum of throughputs of the GPFS filesystems that have been mounted. If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 506</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Total Open and Close Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS OEPN and CLOSE Operations of each node  using the 'mmpmon' io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a node, from the application point of view at the GPFS filesystem layer. The io_s request presents this as a sum for the entire node. Values are displayed for only those nodes that have Galileo Agent Installed. The throughput values are the sum of throughputs of the GPFS filesystems that have been mounted. If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 507</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Open Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays  GPFS OPEN  Operations of each node  using the 'mmpmon' io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a node, from the application point of view at the GPFS filesystem layer. The io_s request presents this as a sum for the entire node. Values are displayed for only those nodes that have Galileo Agent Installed. The throughput values are the sum of throughputs of the GPFS filesystems that have been mounted. If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 508</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Close Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays  GPFS CLOSE Operations of each node  using the 'mmpmon' io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a node, from the application point of view at the GPFS filesystem layer. The io_s request presents this as a sum for the entire node. Values are displayed for only those nodes that have Galileo Agent Installed. The throughput values are the sum of throughputs of the GPFS filesystems that have been mounted. If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 509</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Waiters
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart indicates the number GPFS waiters of few important categories on a node. The number of waiters and the wait times is indication of a GPFS I/O bottleneck on  a node. This chart can used to determine if there are any Storage and Network issues on a particular node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 510</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Open Files
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart indicates the number of files in the GPFS File Cache on a node. This chart can be used to determine if a particular node is caching more files than the other nodes in the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 511</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS READ and WRITE throughput of each Filesystem mounted on a node. The values are collected using the 'mmpmon' command with 'fs_io_s' option. This chart is the indication of the GPFS I/O service-rate of a Filesystem on a node, from the application point of view at the GPFS filesystem layer.   Values are displayed for only those nodes that have Galileo GPFS Agent Installed. The throughput values are for each GPFS Filesystem mounted on a node.  If no  GPFS fileystems are mounted on a node, then the GPFS Filesystem throughput of the throughput of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster for a specific Filesystem, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 512</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS READ throughput in KB/Sec of each Filesystem mounted on a node. The values are collected using the 'mmpmon' command with 'fs_io_s' option. This chart is the indication of the GPFS I/O service-rate of a Filesystem on a node, from the application point of view at the GPFS filesystem layer.   Values are displayed for only those nodes that have Galileo GPFS Agent Installed. The throughput values are for each GPFS Filesystem mounted on a node.  If no  GPFS fileystems are mounted on a node, then the GPFS Filesystem throughput of the throughput of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster for a specific Filesystem, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 513</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS WRITE throughput in KB/Sec of each Filesystem mounted on a node. The values are collected using the 'mmpmon' command with 'fs_io_s' option. This chart is the indication of the GPFS I/O service-rate of a Filesystem on a node, from the application point of view at the GPFS filesystem layer.   Values are displayed for only those nodes that have Galileo GPFS Agent Installed. The throughput values are for each GPFS Filesystem mounted on a node.  If no  GPFS fileystems are mounted on a node, then the GPFS Filesystem throughput of the throughput of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster for a specific Filesystem, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 514</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Total Read and Write Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS READ and WRITE Operations per second for each GPFS filesystem mounted on the node  using the 'mmpmon' fs_io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a filesystem, from the application point of view at the GPFS filesystem layer. Values are displayed for only those nodes that have Galileo Agent Installed.  If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 515</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Read Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS READ Operations per second for each GPFS filesystem mounted on the node  using the 'mmpmon' fs_io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a filesystem, from the application point of view at the GPFS filesystem layer. Values are displayed for only those nodes that have Galileo Agent Installed.  If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 516</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Write Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS WRITE Operations per second for each GPFS filesystem mounted on the node  using the 'mmpmon' fs_io_s values. This chart indicates GPFS I/O Operations (IOPs)  rate of a filesystem, from the application point of view at the GPFS filesystem layer. Values are displayed for only those nodes that have Galileo Agent Installed.  If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 517</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Total Open and Close Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS OPEN and CLOSE Operations per second for each GPFS filesystem mounted on the node  using the 'mmpmon' fs_io_s values. This chart indicates GPFS Metadata I/O Operations (IOPs)  rate of a filesystem, from the application point of view at the GPFS filesystem layer. Values are displayed for only those nodes that have Galileo Agent Installed.  If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 518</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Open Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS OPEN  Operations per second for each GPFS filesystem mounted on the node  using the 'mmpmon' fs_io_s values. This chart indicates GPFS Metadata I/O Operations (IOPs)  rate of a filesystem, from the application point of view at the GPFS filesystem layer. Values are displayed for only those nodes that have Galileo Agent Installed.  If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 519</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Close Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart displays sum of GPFS CLOSE  Operations per second for each GPFS filesystem mounted on the node  using the 'mmpmon' fs_io_s values. This chart indicates GPFS Metadata I/O Operations (IOPs)  rate of a filesystem, from the application point of view at the GPFS filesystem layer. Values are displayed for only those nodes that have Galileo Agent Installed.  If no  GPFS fileystems are mounted on a node, then the GPFS operations of that node is considered as null.  The 'mmpmon' values are collected for every 10 secs and aggregated based on the time period chosen.                                                                                                                                           Since these are discrete samples, there can be variations in the individual results. For example, there may be other activity on the node or interconnection fabric. I/O size, file system block size, and buffering also affect results. There can be many reasons why adjacent values differ. This must be taken into account when building analysis tools that read mmpmon output and interpreting results.                                The zero rates in the chart  could be caused by reasons such as no I/O requests reaching GPFS during that time period (the application issued none, or requests were satisfied by buffered data at a layer above GPFS), the node becoming busy with other work (causing the application to be undispatched), or other reasons.                          This chart can be used to determine: -GPFS data usage patterns at a particular time of the day, -if a node is serving significantly more I/O than other nodes in the cluster, -the total I/O demand the applications are placing on the GPFS cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 520</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Average Read IO op Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 521</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Average Write IO op Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 522</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Average Read IO Op Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 523</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Average Write IO Op Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 524</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Read IO Counts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 525</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Write IO Counts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 526</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Read IO Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 527</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Write IO Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 528</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Total/Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the TOTAL and USED sizes of each GPFS filesystem in the cluster. The data is collected every 30 min using 'mmdf' command.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 529</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Total Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the TOTAL sizes of each GPFS filesystem in the cluster. The data is collected every 30 min using 'mmdf' command.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 530</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Used Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the USED sizes of each GPFS filesystem in the cluster and how they have changed over a period of time. This chart can be helpful in identifying the usage trend of each filesystem for capacity planning. The data is collected every 30 min using 'mmdf' command.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 531</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Free Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the FREE sizes of each GPFS filesystem in the cluster. The data is collected every 30 min using 'mmdf' command. This chart can be very useful to quickly identify the average spare capacity of each filesystem over a specific period of time.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 532</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem % Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the USED size against TOTAL size in percentage of each GPFS filesystem in the cluster and how they have changed over a period of time. This chart can be helpful in identifying the usage trend of each filesystem for capacity planning. The data is collected every 30 min using 'mmdf' command.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 533</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem % Free
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the FREE sizes against TOTAL size in percentage of each GPFS filesystem in the cluster. The data is collected every 30 min using 'mmdf' command. This chart can be very useful to quickly identify the average spare capacity of each filesystem over a specific period of time.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 534</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Max/Used Inodes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Maximum Inodes allocated to the filesystem and Used Inodes over period of time. This chart is helpful in determining number of files created or deleted over a period of time.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 535</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Max Inodes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Maximum Inodes allocated to the filesystem.  The Maximum Inodes indicate the the maximum number of GPFS Files,Directories and Links that the GPFS filesystem can hold.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 536</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Used Inodes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Used Inodes allocated to the filesystem.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 537</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Free Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows FREE Inodes for each filesystem.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 538</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem % Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows Used Inodes against Allocated Inodes of each file system in percentage.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 539</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem % Free
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows FreeInodes against Allocated Inodes of each file system in percentage.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 540</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem % Defragmentation
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows defragmentation of each GPFS filesystem. In a ideal condition the defragmentation is not expected to exceed 10%. You can run 'mmdefrag' command if you see significant defragmentation for a specific filesystem. You can run the GPFS defrag command while the file systems are mounted. However, for better results, unmount the GPFS file system before performing the defragmentation operation. If there is no space in fragments or if the mmdefragfs command does not free up space, add additional disks (NSDs) to the file system to create space.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 541</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    HSM Total Size and Pre-Migrated Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 542</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    HSM Migrated Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 543</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    HSM # Pre-Migrated Files
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 544</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    HSM # Migrated files
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 545</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Fileset Quota Total/Used Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        GPFS utilizes a file system object called a fileset. A fileset is a subtree of a file system namespace that in many respects behaves like an independent file system. Filesets provide a means of partitioning the file system to allow administrative operations at a finer granularity than the entire filesystem. GPFS supports independent and dependent filesets. An independent fileset is a fileset with its own inode space. This chart shows all filesets that are created in each GPFS filesystem with the allocated GPFS quota and currently used quota sizes. This chart helps to identify the trends in quota usage over a period of time so that quotas for each fileset can be managed effectively. You can use 'mmedquota' command either to reduce or increase the allocated quota of a fileset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 546</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Fileset Quota Total Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        GPFS utilizes a file system object called a fileset. A fileset is a subtree of a file system namespace that in many respects behaves like an independent file system. Filesets provide a means of partitioning the file system to allow administrative operations at a finer granularity than the entire filesystem. GPFS supports independent and dependent filesets. An independent fileset is a fileset with its own inode space. This chart shows all filesets that are created in each GPFS filesystem with the allocated GPFS quota of each fileset. This chart helps to identify the whether a GPFS fileset quotas are  over or under allocated against the physical size of each GPFS filesystem. You can use 'mmedquota' command either to reduce or increase the allocated quota of a fileset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 547</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Fileset Quota Used Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        GPFS utilizes a file system object called a fileset. A fileset is a subtree of a file system namespace that in many respects behaves like an independent file system. Filesets provide a means of partitioning the file system to allow administrative operations at a finer granularity than the entire filesystem. GPFS supports independent and dependent filesets. An independent fileset is a fileset with its own inode space. This chart shows all filesets that are created in each GPFS filesystem with their current GPFS quota usage. This chart helps to identify the overall GPFS fileset quotas usage   against the physical size of each GPFS filesystem. You can use 'mmedquota' command either to reduce or increase the allocated quota of a fileset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 548</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Fileset Quota Free Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        GPFS utilizes a file system object called a fileset. A fileset is a subtree of a file system namespace that in many respects behaves like an independent file system. Filesets provide a means of partitioning the file system to allow administrative operations at a finer granularity than the entire filesystem. GPFS supports independent and dependent filesets. An independent fileset is a fileset with its own inode space. This chart shows all filesets that are created in each GPFS filesystem with their current free space against the allocated quota. This chart helps to identify whether a particular fileset is constantly reaching its quota limits or it is not using its allocated quota at all.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 549</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Fileset Quota % Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        GPFS utilizes a file system object called a fileset. A fileset is a subtree of a file system namespace that in many respects behaves like an independent file system. Filesets provide a means of partitioning the file system to allow administrative operations at a finer granularity than the entire filesystem. GPFS supports independent and dependent filesets. An independent fileset is a fileset with its own inode space. This chart shows all filesets that are created in each GPFS filesystem with their current GPFS quota usage against its allocated size as a percentage. This chart helps to identify the overall GPFS fileset quotas usage   against the physical size of each GPFS filesystem. You can use 'mmedquota' command either to reduce or increase the allocated quota of a fileset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 550</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Fileset Quota % Free
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        GPFS utilizes a file system object called a fileset. A fileset is a subtree of a file system namespace that in many respects behaves like an independent file system. Filesets provide a means of partitioning the file system to allow administrative operations at a finer granularity than the entire filesystem. GPFS supports independent and dependent filesets. An independent fileset is a fileset with its own inode space. This chart shows all filesets that are created in each GPFS filesystem with their current free space against the allocated quota as a percentage. This chart helps to identify whether a particular fileset is constantly reaching its quota limits or it is not using its allocated quota at all.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 551</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool Total/Used Sizes
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the TOTAL and USED sizes of each GPFS storage pool within a filesystem. Physically, a storage pool is a collection of disks or RAID arrays. Storage pools also allow you to group multiple storage systems within a file system. Using storage pools, you can create tiers of storage by grouping storage devices based on performance, locality, or reliability characteristics.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 552</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool Total Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the TOTAL sizes of each GPFS storage pool within a filesystem. Physically, a storage pool is a collection of disks or RAID arrays. Storage pools also allow you to group multiple storage systems within a file system.  Using storage pools, you can create tiers of storage by grouping storage devices based on performance, locality, or reliability characteristics.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 553</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool Used Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Physically, a storage pool is a collection of disks or RAID arrays. Storage pools also allow you to group multiple storage systems within a file system.  Using storage pools, you can create tiers of storage by grouping storage devices based on performance, locality, or reliability characteristics. This chart shows the USED sizes of each GPFS storage pool within a filesystem.  This chart is helpful in identifying the trends of each storage pool usage over a period of time and adjust the sizes of each pool effectively.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 554</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool Free Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Physically, a storage pool is a collection of disks or RAID arrays. Storage pools also allow you to group multiple storage systems within a file system.  Using storage pools, you can create tiers of storage by grouping storage devices based on performance, locality, or reliability characteristics. This chart shows the FREE sizes of each GPFS storage pool within a filesystem.  This chart is helpful in identifying the trends of each storage pool usage over a period of time and adjust the sizes of each pool effectively.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 555</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool % Used
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Physically, a storage pool is a collection of disks or RAID arrays. Storage pools also allow you to group multiple storage systems within a file system.  Using storage pools, you can create tiers of storage by grouping storage devices based on performance, locality, or reliability characteristics. This chart shows the percentage of  USED sizes of each GPFS storage pool within a filesystem.  This chart is helpful in identifying the trends of each storage pool usage over a period of time and adjust the sizes of each pool effectively.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 556</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool % Free
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Physically, a storage pool is a collection of disks or RAID arrays. Storage pools also allow you to group multiple storage systems within a file system.  Using storage pools, you can create tiers of storage by grouping storage devices based on performance, locality, or reliability characteristics. This chart shows the percentage of  FREE sizes of each GPFS storage pool within a filesystem.  This chart is helpful in identifying the trends of each storage pool usage over a period of time and adjust the sizes of each pool effectively.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 557</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host CPU %Busy
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows CPU utilization (system+user) of each node in the GPFS cluster where the Galileo GPFS Agent is installed and running.  This chart helps to quickly visualize the over all CPU utilization of the cluster and identify if a particular GPFS node is excessively loaded than the other nodes within the cluster.  Further investigation can be done on the node that is excessively loaded by looking at the Galileo OS agent CPU utilization charts of the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 558</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host CPU %User
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows CPU-USER utilization  of each node in the GPFS cluster where the Galileo GPFS Agent is installed and running.  This chart helps to quickly visualize the over all CPU utilization of the cluster and identify if a particular GPFS node is excessively loaded than the other nodes within the cluster.  Further investigation can be done on the node that is excessively loaded by looking at the Galileo OS agent CPU utilization charts of the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 559</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host CPU %System
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows CPU-SYSTEM utilization  of each node in the GPFS cluster where the Galileo GPFS Agent is installed and running.  This chart helps to quickly visualize the over all CPU utilization of the cluster and identify if a particular GPFS node is excessively loaded than the other nodes within the cluster.  Further investigation can be done on the node that is excessively loaded by looking at the Galileo OS agent CPU utilization charts of the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 560</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host CPU %Wait
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows CPU I/O wait utilization  of each node in the GPFS cluster where the Galileo GPFS Agent is installed and running.  This chart helps to quickly visualize the over I/O waits of the cluster and identify any I/O bottlenecks, Storage and SAN related issues. Further investigation at the Galileo OS agent CPU utilization charts of the node.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 561</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Total Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Total memory available on each GPFS nodes where the Galileo OS Agent installed and running.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 562</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Used Memory
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the USED memory available on each GPFS nodes where the Galileo OS Agent installed and running.  This chart helps to identify the overall memory usage within the cluster and identify any memory related issues of a particular node within the cluster.  Further investigation can be done using the Galileo OS Agent charts of a specific node with the memory issues.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 563</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the overall GPFS NSD Disk I/O total (READ + WRITE) throughput of each node that has Galileo GPFS agent installed within the cluster.  Each GPFS NSD is tagged in the format as GPFS Node:NSD Name:Local Dev on the node. Using this chart you can  easily visualize the overall GPFS disk I/O and quickly identify if the Disk I/O is balanced across the cluster. This chart also helps to identify any I/O performance issues,  and bottlenecks and drill down to a specific GPFS node within the cluster and to a specific NSD on that node with its mapped  local device name for a complete in-depth performance analysis.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 564</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Read Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the overall GPFS NSD Disk I/O READ  throughput of each node that has Galileo GPFS agent installed within the cluster.  Each GPFS NSD is tagged in the format as GPFS Node:NSD Name:Local Dev on the node. Using this chart you can  easily visualize the overall GPFS disk I/O and quickly identify if the Disk I/O is balanced across the cluster. This chart also helps to identify any I/O performance issues,  and bottlenecks and drill down to a specific GPFS node within the cluster and to a specific NSD on that node with its mapped  local device name for a complete in-depth performance analysis.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 565</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the overall GPFS NSD Disk I/O WRITE  throughput of each node that has Galileo GPFS agent installed within the cluster.  Each GPFS NSD is tagged in the format as GPFS Node:NSD Name:Local Dev on the node. Using this chart you can  easily visualize the overall GPFS disk I/O and quickly identify if the Disk I/O is balanced across the cluster. This chart also helps to identify any I/O performance issues,  and bottlenecks and drill down to a specific GPFS node within the cluster and to a specific NSD on that node with its mapped  local device name for a complete in-depth performance analysis.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 566</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the overall GPFS NSD Disk total IOPs  (READ + WRITE ) of each node that has Galileo GPFS agent installed within the cluster.  Each GPFS NSD is tagged in the format as GPFS Node:NSD Name:Local Dev on the node. Using this chart you can  easily visualize the overall GPFS disk I/O and quickly identify if the Disk I/O is balanced across the cluster. This chart also helps to identify any I/O performance issues,  and bottlenecks and drill down to a specific GPFS node within the cluster and to a specific NSD on that node with its mapped  local device name for a complete in-depth performance analysis.  You can also get a better understanding of your  GPFS applications I/O behavior by comparing the Disk I/O throughput and Disk IOPs charts together.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 567</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Read Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the overall GPFS NSD Disk READ IOPs  of each node that has Galileo GPFS agent installed within the cluster.  Each GPFS NSD is tagged in the format as GPFS Node:NSD Name:Local Dev on the node. Using this chart you can  easily visualize the overall GPFS disk I/O and quickly identify if the Disk I/O is balanced across the cluster. This chart also helps to identify any I/O performance issues,  and bottlenecks and drill down to a specific GPFS node within the cluster and to a specific NSD on that node with its mapped  local device name for a complete in-depth performance analysis.  You can also get a better understanding of your  GPFS applications I/O behavior by comparing the Disk I/O throughput and Disk IOPs charts together.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 568</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Disk Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the overall GPFS NSD Disk WRITE IOPs  of each node that has Galileo GPFS agent installed within the cluster.  Each GPFS NSD is tagged in the format as GPFS Node:NSD Name:Local Dev on the node. Using this chart you can  easily visualize the overall GPFS disk I/O and quickly identify if the Disk I/O is balanced across the cluster. This chart also helps to identify any I/O performance issues,  and bottlenecks and drill down to a specific GPFS node within the cluster and to a specific NSD on that node with its mapped  local device name for a complete in-depth performance analysis.  You can also get a better understanding of your  GPFS applications I/O behavior by comparing the Disk I/O throughput and Disk IOPs charts together.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 569</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Receive + Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Network Throughput (SENT+RECEIVED) in KB/sec for each GPFS node that has Galileo GPFS agent installed and running. The chart shows the network throughput on the primary Ethernet network interface GPFS is using. This chart identifies to visualize the overall GPFS cluster network throughput and identify network related issues of a specific node within the cluster. This chart also helps if a node is doing significantly more network I/O than other nodes within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 570</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Receive Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Network RECEIVED Throughput  in KB/sec for each GPFS node that has Galileo GPFS agent installed and running. The chart shows the network throughput on the primary Ethernet network interface GPFS is using. This chart identifies to visualize the overall GPFS cluster network throughput and identify network related issues of a specific node within the cluster. This chart also helps if a node is doing significantly more network I/O than other nodes within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 571</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Network SENT Throughput  in KB/sec for each GPFS node that has Galileo GPFS agent installed and running. The chart shows the network throughput on the primary Ethernet network interface GPFS is using. This chart identifies to visualize the overall GPFS cluster network throughput and identify network related issues of a specific node within the cluster. This chart also helps if a node is doing significantly more network I/O than other nodes within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 572</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Packet Receive + Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Network Throughput (SENT+RECEIVED) in Packets/sec for each GPFS node that has Galileo GPFS agent installed and running. The chart shows the network throughput on the primary Ethernet network interface GPFS is using. This chart identifies to visualize the overall GPFS cluster network throughput and identify network related issues of a specific node within the cluster. This chart also helps if a node is doing significantly more network I/O than other nodes within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 573</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Packet Receive Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Network RECEIVED Throughput  in Packets/sec for each GPFS node that has Galileo GPFS agent installed and running. The chart shows the network throughput on the primary Ethernet network interface GPFS is using. This chart identifies to visualize the overall GPFS cluster network throughput and identify network related issues of a specific node within the cluster. This chart also helps if a node is doing significantly more network I/O than other nodes within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 574</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Host Network Packet Send Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the Network SENT Throughput  in Packets/sec for each GPFS node that has Galileo GPFS agent installed and running. The chart shows the network throughput on the primary Ethernet network interface GPFS is using. This chart identifies to visualize the overall GPFS cluster network throughput and identify network related issues of a specific node within the cluster. This chart also helps if a node is doing significantly more network I/O than other nodes within the cluster.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 600</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows GPFS throughput ( READ+WRITE) in KB/Sec of this particular node within the cluster. These metrics are collected using GPFS 'mmpmon' command. For a complete GPFS performance analysis charts please select the GPFS cluster name in the Galileo Agent GUI Interface.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 601</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Read and Write Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows GPFS File I/O operations (READ+WRITE) per second  of this particular node within the cluster. These metrics are collected using GPFS 'mmpmon' command. For a complete GPFS performance analysis charts please select the GPFS cluster name in the Galileo Agent GUI Interface.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 602</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Open and Close Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows GPFS File I/O operations (OPEN+CLOSE) per second  of this particular node within the cluster. These metrics are collected using GPFS 'mmpmon' command. For a complete GPFS performance analysis charts please select the GPFS cluster name in the Galileo Agent GUI Interface.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 603</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Waiters
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows various categories of GPFS  I/O Waiters  per second  of this particular node within the cluster. These metrics are collected using GPFS 'mmfsadm' command. For a complete GPFS performance analysis charts please select the GPFS cluster name in the Galileo Agent GUI Interface.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 604</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Open Files
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the number of open files in GPFS File Cache (PagePool)  of this particular node within the cluster. These metrics are collected using GPFS 'mmfsadm' command. For a complete GPFS performance analysis charts please select the GPFS cluster name in the Galileo Agent GUI Interface.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 605</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows throughput ( READ+WRITE) in KB/Sec of each GPFS filesystem mounted on this particular node within the cluster. These metrics are collected using GPFS 'mmpmon' command. For a complete GPFS performance analysis charts please select the GPFS cluster name in the Galileo Agent GUI Interface.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 606</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Read and Write Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows File I/O operations (READ+WRITE) per second  of each GPFS Filesystem mounted on this particular node within the cluster. These metrics are collected using GPFS 'mmpmon' command. For a complete GPFS performance analysis charts please select the GPFS cluster name in the Galileo Agent GUI Interface.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 607</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Filesystem Open and Close Operations
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows File I/O operations (OPEN+CLOSE) per second  of each GPFS Filesystem mounted on this particular node within the cluster. These metrics are collected using GPFS 'mmpmon' command. For a complete GPFS performance analysis charts please select the GPFS cluster name in the Galileo Agent GUI Interface.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 608</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Average IO op Size
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 609</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Average IO Op Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 610</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Read IO Counts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 611</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Write IO Counts
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 612</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Read IO Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 613</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    GPFS I/O Write IO Service Time
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Chart Not Implemented yet.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 650</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Total Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write Front-end throughput rate for each I/O group. Front-end I/O is that initiated by a host, directed at volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 651</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Total Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of Front-end operations issued to each I/O group. Front-end I/O is that initiated by a host, directed at volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 652</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Total Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write Back-end throughput rate for each I/O group. Back-end I/O is that initiated by the SVC or Storwize, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 653</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Total Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of Back-end operations issued by each I/O group. Back-end I/O is that initiated by the SVC or Storwize, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 654</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Total Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write Front-end throughput rate for each SVC or Storwize node. Front-end I/O is that initiated by a host, directed at volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 655</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Total Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of Front-end operations issued to each SVC or Storwize node. Front-end I/O is that initiated by a host, directed at volumes.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 656</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Total Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write Back-end throughput rate for each SVC or Storwize node. Back-end I/O is that initiated by the SVC or Storwize, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 657</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Total Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of Back-end operations issued by each SVC or Storwize node. Back-end I/O is that initiated by the SVC or Storwize, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 658</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool Total Throughput (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write Front-end throughput rate for volumes in each storage pool. Front-end I/O is that initiated by a host, directed at volumes that reside in a given storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 659</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool Total Transfers (Host/Front-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of Front-end operations for volumes in each storage pool. Front-end I/O is that initiated by a host, directed at volumes that reside in a given storage pool.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 660</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool Total Throughput (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write Back-end throughput rate for volumes in each storage pool. Back-end I/O is that initiated by the SVC or Storwize, directed at at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 661</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Storage Pool Total Transfers (Disk/Back-end)
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of Back-end operations for volumes in each storage pool. Back-end I/O is that initiated by the SVC or Storwize, directed at back-end storage arrays.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 662</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Internal Disk Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write throughput rate for each internal disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 663</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Internal Disk Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of operations issued for each internal disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 664</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write throughput rate for each managed disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 665</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Mdisk Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of operations issued for each managed disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 666</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write throughput rate for each volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 667</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write rate of operations issued for each volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 700</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Total Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the write throughput rate into the write cache, by volume. This includes writes in fast-write mode, write-through mode, flush-through mode, and cache-full mode.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 701</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Total Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of write operations into the write cache, by volume. This includes writes in fast-write mode, write through mode, flush-through mode, and cache-full mode.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 702</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Fast Write Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the write throughput rate in fast-write mode. Fast-write mode is generally the normal operating mode, in that writes are acknowledged to the host as soon as the write is mirrored in the fast-write cache of the two SVC or Storwize nodes in the I/O group. The host need not wait for the write to be committed to back-end disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 703</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Fast Write Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of write operations in fast-write mode. Fast-write mode is generally the normal operating mode, in that writes are acknowledged to the host as soon as the write is mirrored in the fast-write cache of the two SVC or Storwize nodes in the I/O group. The host need not wait for the write to be committed to back-end disk.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 704</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Write Through Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the write throughput rate in write-through mode. In write-through mode, the write is not acknowledged to the host until the write has been committed to back-end disk. Note that cache-disabled volumes will not be registered in this, or any write cache chart. Cache-disabled volumes are not the same as volumes writing in write-though mode. One reason for a volume to be written in write-through mode is when one node in an I/O group is offline. In that situation, the remaining node switches to write-through mode for writes that would normally be in fast-write mode.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 705</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Write Through Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of write operations in write-through mode. In write-through mode, the write is not acknowledged to the host until the write has been committed to back-end disk. Note that cache-disabled volumes will not be registered in this, or any write cache chart. Cache-disabled volumes are not the same as volumes writing in write-though mode. One reason for a volume to be written in write-through mode is when one node in an I/O group is offline. In that situation, the remaining node switches to write-through mode for writes that would normally be in fast-write mode.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 706</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Flush Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the write throuhput rate in flush-through mode. In flush-through mode, the SVC or Storwize node is actively attempting to empty the write cache of dirty data for a volume. Reasons for a volume to be written in flush-through mode include a FlashCopy mapping entering the preparing state when the volume is the source volume of the FlashCopy mapping, or a volume is transitioning to cache-disabled via user request.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 707</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Flush Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows rate of write operations in flush-through mode. In flush-through mode, the SVC or Storwize node is actively attempting to empty the write cache of dirty data for a volume. Reasons for a volume to be written in flush-through mode include a FlashCopy mapping entering the preparing state when the volume is the source volume of the FlashCopy mapping, or a volume is transitioning to cache-disabled via user request.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 708</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Full Throughput
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the write throughput rate in cache-full mode. In cache-full mode, the SVC or Storwize node's cache partition is full for the storage pool where the volume copy exists. In this scenario, a new track write cannot be accepted into the write cache until another track can be destaged to back-end disk. This results in a one-out, one-in situation, and generally indicates that the back-end disk is unable to sustain the current workload.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 709</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Full Transfers
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of write operations in cache-full mode. In cache-full mode, the SVC or Storwize node's cache partition is full for the storage pool where the volume copy exists. In this scenario, a new track write cannot be accepted into the write cache until another track can be destaged to back-end disk. This results in a one-out, one-in situation, and generally indicates that the back-end disk is unable to sustain the current workload.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 710</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Dirty Write Cache Hits Percentage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of fast-write operations to a volume which resulted in a dirty write cache hit. A dirty write cache hit is a write where, for a given cache track, all sectors being written to that track already contain dirty data. Dirty data is data in the write cache that has not yet been destaged to back-end disk. Dirty write cache hits decrease the number of back-end writes required; for example, if a track is written to cache, then written to cache again prior to the data being destaged to disk, this results in two writes to cache but only one write to back-end disk. A write that spans multiple cache tracks can have both dirty write hits and misses.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 711</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Activity Distribution
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the distribution (in percent) of write operations for the volume, displayed by fast-write mode (Fast), write-through mode (Through), flush-through mode (Flush) and cache-full mode (Overflow). In general, most traffic should be fast-write traffic, with some flush-through traffic for volumes that need to flush periodically (FlashCopy source volumes, for example). Write-through and cache-full traffic might warrant investigation.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 712</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Sector Activity Distribution
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the distribution (in percent) of witten sectors for the volume, displayed by fast-write mode (Fast), write-through mode (Through), flush-through mode (Flush) and cache-full mode (Overflow). In general, most traffic should be fast-write traffic, with some flush-through traffic for volumes that need to flush periodically (FlashCopy source volumes, for example). Write-through and cache-full traffic might warrant investigation.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 713</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Global Mirror Secondary Latency
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows Global Mirror Secondary Latency for each volume. For Global Mirror primary volumes, this shows the latency between the completion of the I/O at the primary site and the completion of the I/O (into mirrored cache) at the secondary site. This is the approximate Recovery Point Objective (RPO) the volume is achieving. For Global Mirror secondary volumes, this shows the latency waiting for writes upon which this write depends.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 714</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Read Cache Data
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of data present in the SVC or Storwize read cache for the volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 715</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Write Cache Data
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the amount of data present in the SVC or Storwize write cache for the volume.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 716</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Host-Attributed Latency
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the combined read and write latency for the volume, that is attributed to the host. For reads, this shows the latency bewtee the time the SVC or Storwize sends a transfer ready signal to the host and the time the host responds to that transfer ready request. For write, this shows the latency between the time the SVC or Storwize sends a transfer ready signal to the host and the time the SVC or Storwize receives the data to be written. Host-attributed latency can be used to identify a host that is a slow-drain device, is malfunctioning, or is misconfigured, etc.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 717</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Volume Host-Attributed Latency Percentage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percent of the combined read and write latency for the volume, that is attributed to the host. For reads, this shows the latency bewteen the time the SVC or Storwize sends a transfer ready signal to the host and the time the host responds to that transfer ready signal. For writes, this shows the latency between the time the SVC or Storwize sends a transfer ready signal to the host and the time the SVC or Storwize receives the data to be written. Host-attributed latency can be used to identify a host that is a slow-drain device, is malfunctioning, or is misconfigured, etc.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 718</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Dirty Write Cache Hits Percentage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of fast-write operations to a node which resulted in a dirty write cache hit. A dirty write cache hit is a write where, for a given cache track, all sectors being written to that track already contain dirty data. Dirty data is data in the write cache that has not yet been destaged to back-end disk. Dirty write cache hits decrease the number of back-end writes required; for example, if a track is written to cache, then written to cache again prior to the data being destaged to disk, this results in two writes to cache but only one write to back-end disk. A write that spans multiple cache tracks can have both dirty write hits and misses.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 719</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Cache Activity Distribution
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the distribution (in percent) of write operations for the node, displayed by fast-write mode (Fast), write-through mode (Through), flush-through mode (Flush) and cache-full mode (Overflow). In general, most traffic should be fast-write traffic, with some flush-through traffic for volumes that need to flush periodically (FlashCopy source volumes, for example). Write-through and cache-full traffic might warrant investigation.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 720</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Write Cache Sector Activity Distribution
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the distribution (in percent) of witten sectors for the node, displayed by fast-write mode (Fast), write-through mode (Through), flush-through mode (Flush) and cache-full mode (Overflow). In general, most traffic should be fast-write traffic, with some flush-through traffic for volumes that need to flush periodically (FlashCopy source volumes, for example). Write-through and cache-full traffic might warrant investigation.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 721</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Node Cache Partition Fullness
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the minimum (Min), average (Ave), and maximum (Max) cache partition fullness for the partition during the sample period. Extended periods above 80% can indicate the back-end disk is unable to maintain the destage rate necessary to sustain the front-end workload.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 722</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Dirty Write Cache Hits Percentage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of fast-write operations to an I/O group which resulted in a dirty write cache hit. A dirty write cache hit is a write where, for a given cache track, all sectors being written to that track already contain dirty data. Dirty data is data in the write cache that has not yet been destaged to back-end disk. Dirty write cache hits decrease the number of back-end writes required; for example, if a track is written to cache, then written to cache again prior to the data being destaged to disk, this results in two writes to cache but only one write to back-end disk. A write that spans multiple cache tracks can have both dirty write hits and misses.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 723</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Cache Activity Distribution
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the distribution (in percent) of write operations for the I/O group, displayed by fast-write mode (Fast), write-through mode (Through), flush-through mode (Flush) and cache-full mode (Overflow). In general, most traffic should be fast-write traffic, with some flush-through traffic for volumes that need to flush periodically (FlashCopy source volumes, for example). Write-through and cache-full traffic might warrant investigation.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 724</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    I/O Group Write Cache Sector Activity Distribution
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the distribution (in percent) of witten sectors for the I/O group, displayed by fast-write mode (Fast), write-through mode (Through), flush-through mode (Flush) and cache-full mode (Overflow). In general, most traffic should be fast-write traffic, with some flush-through traffic for volumes that need to flush periodically (FlashCopy source volumes, for example). Write-through and cache-full traffic might warrant investigation.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 725</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Dirty Write Cache Hits Percentage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of fast-write operations to the cluster which resulted in a dirty write cache hit. A dirty write cache hit is a write where, for a given cache track, all sectors being written to that track already contain dirty data. Dirty data is data in the write cache that has not yet been destaged to back-end disk. Dirty write cache hits decrease the number of back-end writes required; for example, if a track is written to cache, then written to cache again prior to the data being destaged to disk, this results in two writes to cache but only one write to back-end disk. A write that spans multiple cache tracks can have both dirty write hits and misses.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 726</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Write Cache Activity Distribution
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the distribution (in percent) of write operations for the cluster, displayed by fast-write mode (Fast), write-through mode (Through), flush-through mode (Flush) and cache-full mode (Overflow). In general, most traffic should be fast-write traffic, with some flush-through traffic for volumes that need to flush periodically (FlashCopy source volumes, for example). Write-through and cache-full traffic might warrant investigation.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 727</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Write Cache Sector Activity Distribution
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the distribution (in percent) of witten sectors for the cluster, displayed by fast-write mode (Fast), write-through mode (Through), flush-through mode (Flush) and cache-full mode (Overflow). In general, most traffic should be fast-write traffic, with some flush-through traffic for volumes that need to flush periodically (FlashCopy source volumes, for example). Write-through and cache-full traffic might warrant investigation.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 728</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port BB Credit Zero Percentage
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the percentage of time a port has zero buffer-to-buffer (BB) credits available. When a port has zero BB credits available, it cannot transmit frames until a BB credit is released. High zero BB credit time can indicate a bottleneck is present in the SAN fabric. Potential causes of BB credit exhaustion include ports performing near their theoretical throughput limit, congested ISLs, and slow-drain host or storage devices. Zero BB credits on an SVC or Storwize port does not necessarily indicate that the SVC or Storwize port is the cause of the problem. Zero BB credit issues can often be traced to devices elsewhere in the SAN fabric.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 729</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Link Failure Count
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the cumulative count of link failure errors reported by the port since the node last reset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 730</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Loss-of-Synchronization Count
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the cumulative count of loss-of-synchronization errors reported by the port since the node last reset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 731</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Loss-of-Signal Count
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the cumulative count of loss-of-signal errors reported by the port since the node last reset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 732</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Primitive Sequence Protocol Error Count
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the cumulative count of primitive sequence protocol errors reported by the port since the node last reset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 733</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Invalid Transmission Word Count
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the cumulative count of invalid transmission word errors reported by the port since the node last reset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 734</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Invalid CRC Count
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the cumulative count of invalid Cyclic Redundancy Check (CRC) errors reported by the port since the node last reset.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 735</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Link Failure Rate
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of link failure errors reported by the port during the sample interval.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 736</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Loss-of-Synchronization Rate
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of loss-of-synchronization errors reported by the port during the sample interval.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 737</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Loss-of-Signal Rate
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of loss-of-signal errors reported by the port during the sample interval.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 738</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Primitive Sequence Protocol Error Rate
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of primitive sequence protocol errors reported by the port during the sample interval.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 739</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Invalid Transmission Word Rate
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of invalid transmission word errors reported by the port during the sample interval.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 740</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Port Invalid CRC Rate
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        This chart shows the rate of invalid Cyclic Redundancy Check (CRC) errors reported by the port during the sample interval.
      </div>
    </div>
  </div>
</div>
<h1>Chart - 741</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Cluster Replication Throughput Summary
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>
          This chart shows the throughput of traffic SENT and RECEIVED by all ports in this cluster from other nodes in REMOTE clusters.
        </p>
        <p>
          This traffic includes:
        </p>
        <ul>
          <li>Global Mirror replication traffic</li>
          <li>Metro Mirror replication traffic</li>
          <li>Inter-Cluster heartbeat traffic</li>
        </ul>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10000</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Capacity Summary Information for SVC
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Two pills that present capacity information as of the last receipt of data from the SVC.
      </div>
      <div class='definitions'>
        <ul>
          <li>
            <b>
              Cluster Capacity
            </b>
            Allocation of managed/unmanaged mdisks in the cluster
          </li>
          <li>
            <b>
              Virtual Capacity
            </b>
            Managed disk allocated to volumes. Includes any overallocation created by thin-provisioned volumes.
          </li>
        </ul>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          and/or refer to the
          <b>
            Configuration Data
          </b>
          group for more information.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10001</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for SVC
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Summary of configuration information as of the last receipt of data from the SVC.
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10002</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Capacity Summary Information for DS
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        A pill that presents capacity information as of the last receipt of data from the DS.
      </div>
      <div class='definitions'>
        <ul>
          <li>
            <b>
              Subsystem Capacity
            </b>
            Allocation of managed/unmanaged drives in the cluster
          </li>
        </ul>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          and/or refer to the
          <b>
            Configuration Data
          </b>
          group for more information.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10003</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for DS
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Summary of configuration information as of the last receipt of data from the DS.
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10004</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Capacity Summary Information for XIV
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        A pill that presents capacity information as of the last receipt of data from the XIV.
      </div>
      <div class='definitions'>
        <ul>
          <li>
            <b>
              Hard Capacity
            </b>
            Capacity from the perspective of hard limits
          </li>
          <li>
            <b>
              Soft Capacity
            </b>
            Capacity from the perspective of soft limits
          </li>
        </ul>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          and/or refer to the
          <b>
            Configuration Data
          </b>
          group for more information.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10005</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for XIV
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Summary of configuration information as of the last receipt of data from the XIV.
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10006</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for AIX
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Summary of configuration information as of the last receipt of data from the host.
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10007</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Capacity Information for AIX
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        One pill for each filesystem type that represents the aggregate capacity as of the last receipt of data from the host.
      </div>
      <div class='definitions'>
        <ul>
          <li>
            <b>
              Filesystem Capacity (
              <i>
                type
              </i>
              )
            </b>
            Allocation of used/free filesystem space for the given
            <i>
              type
            </i>
            on the host
          </li>
        </ul>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          ) beside each
          <b>
            Filesystem Capacity
          </b>
          header for details of each particular filesystem type.  Additionally, refer to the
          <b>
            Configuration Data
          </b>
          group for more information.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10009</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for Linux
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Summary of configuration information as of the last receipt of data from the host.
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10010</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Capacity Information for Linux
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        One pill for each filesystem type that represents the aggregate capacity as of the last receipt of data from the host.
      </div>
      <div class='definitions'>
        <ul>
          <li>
            <b>
              Filesystem Capacity (
              <i>
                type
              </i>
              )
            </b>
            Allocation of used/free filesystem space for the given
            <i>
              type
            </i>
            on the host
          </li>
        </ul>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          ) beside each
          <b>
            Filesystem Capacity
          </b>
          header for details of each particular filesystem type.  Additionally, refer to the
          <b>
            Configuration Data
          </b>
          group for more information.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10015</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for Windows
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Summary of configuration information as of the last receipt of data from the host.
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10016</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Capacity Information for Windows
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        One pill that represents the aggregate filesystem capacity as of the last receipt of data from the host.
      </div>
      <div class='definitions'>
        <ul>
          <li>
            <b>
              Filesystem Capacity
            </b>
            Allocation of used/free filesystem space on the host
          </li>
        </ul>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          and/or refer to the
          <b>
            Configuration Data
          </b>
          group for more information.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10017</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for Frame
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        <p>
          Summary of configuration information as of the last receipt of data from the frame.
        </p>
        <p>
          The
          <b>Network Interfaces</b>
          and
          <b>Fiber Adapters</b>
          listed are only the dedicated, physical adapters that are allocated to currently active LPARs.  Additionally, IVE network adapters in LHE mode are also listed.  Any virtual network/fiber adapters, or those that are installed but not allocated to an active LPAR are not included.
        </p>
        <p>
          If IVE LHE network adapters are in use, one can identify all active LPARs utilizing a particular IVE port by specifying a location filter equal to that of the physical IVE port in the
          <b>Network Interfaces</b>
          table.
        </p>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10031</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for SONAS
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Summary of configuration information as of the last receipt of data from the SONAS.
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10032</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Capacity Summary Information for SONAS
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        A pill that presents capacity information as of the last receipt of data from the SONAS.
      </div>
      <div class='definitions'>
        <ul>
          <li>
            <b>
              Cluster Capacity
            </b>
            Total capacity of the Cluster (summation of disks available to the cluster).
          </li>
          <li>
            <b>
              Pools Capacity
            </b>
            The summary of the capacitly allocated to the pools.
          </li>
          <li>
            <b>
              Filesystems Capacity
            </b>
            The summary of the capacitly allocation to the filesystems.
          </li>
        </ul>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          and/or refer to the
          <b>
            Configuration Data
          </b>
          group for more information.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10051</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Configuration Information for GPFS
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        Summary of configuration information as of the last receipt of data from the GPFS cluster.
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          for more information.
        </p>
        <p>
          <b>
            Click
          </b>
          (
          <span>...</span>
          )
          to expand partially-hidden fields.
        </p>
      </div>
    </div>
  </div>
</div>
<h1>Chart - 10052</h1>
<!DOCTYPE html>
<div>
  <h2 class='title'>
    Capacity Summary Information for GPFS
  </h2>
  <div class='help-content-container'>
    <div class='help-content'>
      <div class='main'>
        A pill that presents capacity information as of the last receipt of data from the GPFS cluster.
      </div>
      <div class='definitions'>
        <ul>
          <li>
            <b>
              Cluster Capacity
            </b>
            Total capacity of the Cluster (summation of disks available to the cluster).
          </li>
          <li>
            <b>
              Pools Capacity
            </b>
            The summary of the capacitly allocated to the pools.
          </li>
          <li>
            <b>
              Filesystems Capacity
            </b>
            The summary of the capacitly allocation to the filesystems.
          </li>
        </ul>
      </div>
      <div class='notes'>
        <p>
          <b>
            Click
          </b>
          (
          <span class='ui-icon ui-icon-extlink'></span>
          )
          and/or refer to the
          <b>
            Configuration Data
          </b>
          group for more information.
        </p>
      </div>
    </div>
  </div>
</div>
